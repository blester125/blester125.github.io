<!DOCTYPE html>
<html lang="en">
  <head>
    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script
      async
      src="https://www.googletagmanager.com/gtag/js?id=UA-156541294-1"
    ></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag() {
        dataLayer.push(arguments);
      }
      gtag("js", new Date());
      gtag("config", "UA-156541294-1");
    </script>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="description" content="Machine Learning Research Scientist." />
    <meta name="author" content="Brian Lester" />

    <title>Brian Lester</title>

    <!-- Third Party CSS -->
    <link
      href="https://stackpath.bootstrapcdn.com/bootstrap/3.3.6/css/bootstrap.min.css"
      rel="stylesheet"
      integrity="sha384-1q8mTJOASx8j1Au+a5WDVnPi2lkFfwwEAa8hDDdjZlpLegxhjVME1fgjWPGmkzs7"
      crossorigin="anonymous"
    />

    <!-- Fonts -->
    <link
      rel="stylesheet"
      href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.0/css/all.min.css"
      integrity="sha256-ybRkN9dBjhcS2qrW1z+hfCxq+1aBdwyQM5wlQoQVt/0="
      crossorigin="anonymous"
    />
    <link
      rel="stylesheet"
      href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css"
    />
    <link
      href="https://fonts.googleapis.com/css?family=Montserrat:400,700"
      rel="stylesheet"
      type="text/css"
    />
    <link
      href="https://fonts.googleapis.com/css?family=Kaushan+Script"
      rel="stylesheet"
      type="text/css"
    />
    <link
      href="https://fonts.googleapis.com/css?family=Droid+Serif:400,700,400italic,700italic"
      rel="stylesheet"
      type="text/css"
    />
    <link
      href="https://fonts.googleapis.com/css?family=Roboto+Slab:400,100,300,700"
      rel="stylesheet"
      type="text/css"
    />

    <!-- HTML5 Shim and Respond.js IE8 support of HTML5 elements and media queries -->
    <!-- WARNING: Respond.js doesn't work if you view the page via file:// -->
    <!--[if lt IE 9]>
      <script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js" integrity="sha384-0s5Pv64cNZJieYFkXYOTId2HMA2Lfb6q2nAcx2n0RTLUnCAoTTsS0nKEO27XyKcY" crossorigin="anonymous"></script>
      <script src="https://oss.maxcdn.com/libs/respond.js/1.4.2/respond.min.js" integrity=sha384-ZoaMbDF+4LeFxg6WdScQ9nnR1QC2MIRxA1O9KWEXQwns1G8UNyIEZIQidzb0T1fo" crossorigin="anonymous"></script>
    <![endif]-->

    <!-- favicon, the logo in the tab -->
    <link rel="icon" href="/static/img/favicon.ico" type="image/x-icon" />
    <link
      rel="shortcut icon"
      href="/static/img/favicon.ico"
      type="image/x-icon"
    />

    <!-- Third Party Javascript -->
    <script
      src="https://code.jquery.com/jquery-1.11.1.min.js"
      integrity="sha256-VAvG3sHdS5LqTT+5A/aeq/bZGa/Uj04xKxY8KM/w9EE="
      crossorigin="anonymous"
    ></script>
    <script
      src="https://cdn.jsdelivr.net/npm/vue@2.6.11"
      integrity="sha384-OZmxTjkv7EQo5XDMPAmIkkvywVeXw59YyYh6zq8UKfkbor13jS+5p8qMTBSA1q+F"
      crossorigin="anonymous"
    ></script>
    <script
      src="https://stackpath.bootstrapcdn.com/bootstrap/3.3.6/js/bootstrap.min.js"
      integrity="sha384-0mSbJDEHialfmuBBQP6A4Qrprq5OVfW37PRR3j5ELqxss1yVqOtnepnHVP9aJ7xS"
      crossorigin="anonymous"
    ></script>
    <script
      src="https://cdnjs.cloudflare.com/ajax/libs/jquery-easing/1.3/jquery.easing.min.js"
      integrity="sha384-mE6eXfrb8jxl0rzJDBRanYqgBxtJ6Unn4/1F7q4xRRyIw7Vdg9jP4ycT7x1iVsgb"
      crossorigin="anonymous"
    ></script>
    <script
      src="https://cdn.rawgit.com/larsgw/citation.js/archive/citation.js/citation-0.4.0-9.min.js"
      integrity="sha384-kJjxdvLlabsAGkfvB39DUjWTIQluK9B53cCYlkLRtAyuhmmC0wgPP3uio4mI2IvS"
      crossorigin="anonymous"
    ></script>
    <script
      src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.4/clipboard.min.js"
      integrity="sha384-8CYhPwYlLELodlcQV713V9ZikA3DlCVaXFDpjHfP8Z36gpddf/Vrt47XmKDsCttu"
      crossorigin="anonymous"
    ></script>

    <!-- MathJax -->
    <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
    <script
      id="MathJax-script"
      async
      src="https://cdn.jsdelivr.net/npm/mathjax@3.0.5/es5/tex-mml-chtml.js"
      crossorigin="anonymous"
    ></script>

    <!-- Custom CSS -->
    <link href="/static/css/agency.css" rel="stylesheet" />
    <link href="/static/css/presentation.css" rel="stylesheet" />
    <link href="/static/css/paper.css" rel="stylesheet" />
    <link href="/static/css/project.css" rel="stylesheet" />
    <link href="/static/css/nav.css" rel="stylesheet" />
    <link href="/static/css/nav-placeholder.css" rel="stylesheet" />
    <link href="/static/css/blog.css" rel="stylesheet" />
    <link href="/static/css/experience.css" rel="stylesheet" />

    <!-- Custom JavaScript -->
    <script src="/static/js/fetch.js"></script>
    <script src="/static/js/references.js"></script>
    <script src="/static/js/blog.js"></script>
    <script>
      $(function () {
        $("#nav").load("static/nav.html", function () {
          // Load the Agency javascript (scroll spy, easing, etc) after the nav bar has been loaded so
          // the script will have elements to find.
          loadScript("/static/js/agency.js");
        });
        $(".social-links").load("static/socials.html");
        $("#footer").load("static/footer.html", function () {
          $(".social-links").load("static/socials.html");
        });
      });
      readFile(
        "static/references/index.txt",
        generateReferences.bind(
          null,
          "publications-container",
          "static/references/"
        )
      );
      readFile(
        "static/blog.json",
        generateBlogs.bind(null, "blog-container", "blog")
      );
    </script>
  </head>

  <body id="page-top" class="index">
    <div id="nav" class="nav-placeholder"></div>
    <!-- Header -->
    <header>
      <div class="container">
        <div class="intro-text">
          <div class="team-member">
            <img
              src="static/img/team/BrianLester.jpg"
              class="img-responsive img-circle"
              alt=""
            />
          </div>
          <div class="intro-heading">Brian Lester</div>
          <div class="team-member">
            <div class="social-links"></div>
          </div>
        </div>
      </div>
    </header>

    <!-- Experience Section -->
    <section id="experience">
      <div class="container">
        <div class="row">
          <div class="col-lg-12 text-center">
            <h2 class="section-heading">Experience</h2>
            <h3 class="section-subheading text-muted">Work History</h3>
          </div>
        </div>
        <div class="row">
          <div class="col-lg-12">
            <ul class="timeline">
              <!-- Begin Google AI Resident -->
              <li class="timeline-inverted">
                <div class="timeline-image">
                  <img
                    class="img-circle img-responsive"
                    src="static/img/experience/google-ai.png"
                  />
                </div>
                <div class="timeline-panel">
                  <div class="timeline-heading">
                    <h4>Google</h4>
                    <h4 class="subheading">October 2020&#8211;Present</h4>
                  </div>
                  <div class="timeline-body">
                    <p class="text-muted job-right">
                      <strong>AI Resident</strong>&#8212;Working on Natural
                      Language Processing and Understanding.
                    </p>
                    <p class="text-muted job-right">
                      Interesting in efficiently leveraging massive pre-trained
                      transformers and adding structured prediction atop
                      powerful local features created by large contextual
                      embeddings.
                    </p>
                  </div>
                </div>
              </li>
              <!-- Begin Interactions -->
              <li>
                <div class="timeline-image">
                  <img
                    class="img-circle img-responsive"
                    src="static/img/experience/interactions.png"
                  />
                </div>
                <div class="timeline-panel">
                  <div class="timeline-heading">
                    <h4>Interactions</h4>
                    <h4 class="subheading">April 2018&#8211;October 2020</h4>
                  </div>
                  <div class="timeline-body">
                    <p class="text-muted job-left">
                      <strong>Machine Learning Engineer</strong
                      >&#8212;Specialized in using Deep Learning for Natural
                      Language Processing (NLP). Researched new and effective
                      training methods and model architectures, built
                      client-facing models for production, and created
                      infrastructure that enables distributed, cloud-native,
                      training and horizontally scalable model serving.
                    </p>
                    <p class="text-muted job-left">
                      I maintain Mead-Baseline&#8212;our open-source
                      deep-learning toolkit. It is the go to path for all deep
                      learning work (research and production) within the
                      company. I have created performant, batched
                      implementations of various complex neural network
                      architectures including a Conditional Random Field (CRF)
                      and Beam Search.
                    </p>
                    <p class="text-muted job-left">
                      Designed the label space and annotation guidelines for the
                      Natural Language Understanding module of a customer facing
                      dialogue system in the self-service technical support
                      domain for a cyber security company. My design focused on
                      general intents, slot values (which were combined to form
                      complex entities), and relations to cover diverse and
                      complex conversational domain.
                    </p>
                    <p class="text-muted job-left">
                      Created our cloud-native, deep-learning model training
                      platform. Our platform is a Directed Acyclic Graph (DAG)
                      execution engine powered by kubernetes that can run a
                      pipeline of tasks where each step can be anything that can
                      be run inside of a docker container. Our platform
                      automatically parallelizes non-dependent nodes in the DAG
                      (allowing for efficient Hyper Parameter Optimization
                      (HPO)) and can distribute the computation of a single step
                      in the pipeline over multiple GPUs and compute nodes.
                      Using Kubernetes allows for effective sharing of cluster
                      resources among disjoint users. The platform enables
                      building mutli-step pipelines that can transform raw
                      training data into a model that is ready for production.
                    </p>
                    <p class="text-muted job-left">
                      Created and maintain our deep-learning model serving
                      infrastructure. The server, backed by TensorFlow Serving,
                      enables rich Natural Language Understanding (NLU) via
                      cascading calls to a series of deep learning models. Both
                      the server itself and the TensorFlow Serving backend are
                      deployed via Kubernetes. The server includes components
                      that are reusable across clients and also supports an
                      extensive plugin system for client specific operations.
                      This server is currently powering NLU for several
                      production dialogue systems.
                    </p>
                    <p class="text-muted job-left">
                      Created a wide range of Machine Learning models powering
                      client-facing production models. The architectures and
                      tasks range from ConvNets for classification (used in
                      intent detection, text categorization, and sentence
                      segmentation), mention-ranking models for relation
                      extraction, bLSTM-CRF taggers for general purpose tagging
                      (NER, POS, Chunking) as well as client-specific slot
                      filling, to Transformer-based seq2seq models used to
                      automatically suggest agent responses. Production models
                      were also calibrated to produce reliable scores via a mix
                      of post-hoc methods and auxiliary confidence models.
                    </p>
                  </div>
                </div>
              </li>
              <!-- Begin Trove -->
              <li class="timeline-inverted">
                <div class="timeline-image">
                  <img
                    class="img-circle img-responsive"
                    src="static/img/experience/trove.png"
                  />
                </div>
                <div class="timeline-panel">
                  <div class="timeline-heading">
                    <h4>Trove</h4>
                    <h4 class="subheading">March 2017&#8211;April 2018</h4>
                  </div>
                  <div class="timeline-body">
                    <p class="text-muted job-right">
                      <strong>Lead Machine Learning Research Engineer</strong
                      >&#8212;Used machine learning, natural language
                      processing, computer vision, and cutting edge deep neural
                      networks to power improve heuristic based existing
                      features and create new features. Designed and Implemented
                      our model serving infrastructure that processed 200 emails
                      a day. Provided technical leadership to the data science
                      team.
                    </p>
                    <p class="text-muted job-right">
                      Trove would detect and surface sentences in emails that
                      warranted a response to help track emails that were
                      important to reply too. This was originally done via a
                      tangled mess of regular expressions. Using unsupervised
                      methods and iterative refinement I bootstrapped a dataset
                      of these sentences. Using a ConvNet I was able to create a
                      system better than the regex. The ConvNet was also able to
                      account for semantic meaning and we refined the product so
                      that it highlights requests that can be handled via email
                      not just any ask. The results of this model became a
                      staple feature in the annotated email social graph that
                      trove created.
                    </p>
                    <p class="text-muted job-right">
                      Used a neural ranking model to preform coreference
                      resolution by linking anaphors to their antecedents. By
                      replacing pronominal mentions in the question snippets
                      extracted from emails we were able to provide context to
                      the users.
                    </p>
                    <p class="text-muted job-right">
                      Used lexical features from the email as well as
                      connectivity information in the email social graph to
                      identify bot accounts. We used a broad definition of bots
                      to include things like newsletters and automated email
                      from things like github. We used these classification
                      labels to help filter search results.
                    </p>
                  </div>
                </div>
              </li>
              <!-- End Trove -->
              <!-- VISTEON -->
              <li>
                <div class="timeline-image">
                  <img
                    class="img-circle img-responsive"
                    src="static/img/experience/Visteon.png"
                  />
                </div>
                <div class="timeline-panel">
                  <div class="timeline-heading">
                    <h4>Visteon Corporation</h4>
                    <h4 class="subheading">May 2015&#8211;August 2015</h4>
                  </div>
                  <div class="timeline-body">
                    <p class="text-muted job-left">
                      <strong>Software Engineering Intern</strong
                      >&#8212;Specialized in Voice Recognition and User
                      Information Systems.
                    </p>
                    <p class="text-muted job-left">
                      Prototyped and Vetted Dragon Drive Link, an on-board
                      real-time driver information and entertainment application
                      similar to Android Auto.
                    </p>
                    <p class="text-muted job-left">
                      Research, designed, and implemented a system to optimize
                      Voice Recognition used in Production Mazda cars. It
                      dynamically decides if it should display a menu of
                      disambiguation options based on the users past
                      interactions with the system. We patented with system
                      <a
                        href="https://patents.google.com/patent/US9984688B2/en"
                      >
                        (US 9984688B2)
                      </a>
                    </p>
                  </div>
                </div>
              </li>
              <!-- End Visteon -->
            </ul>
          </div>
        </div>
      </div>
    </section>

    <!-- Publications section -->
    <section id="publications" class="bg-light-gray">
      <div class="container">
        <div class="row">
          <div class="col-lg-12 text-center">
            <h2 class="section-heading">Publications</h2>
          </div>
        </div>
        <div id="publications-container">
          <template v-for="pub in publications">
            <div class="paper" :id="pub.id">
              <a class="paper-link" v-bind:href="pub.link">
                <div class="row">
                  <div class="col-lg-1"></div>
                  <div class="col-lg-10">
                    <h3 class="paper-title" v-html="pub.title"></h3>
                    <h4 class="paper-authors">{{ pub.authors }}</h4>
                    <p class="paper-venue">{{ pub.venue }}</p>
                  </div>
                  <div class="col-lg-1"></div>
                </div>
              </a>
              <div class="row">
                <div class="col-lg-1"></div>
                <a
                  class="btn btn-primary paper-button-first"
                  v-bind:href="pub.link"
                  style="margin-left: 5%"
                  >PDF</a
                >
                <a
                  class="btn btn-primary paper-button"
                  v-on:click="showModal(pub.modal_id)"
                  >BibTex</a
                >
                <div
                  class="modal"
                  :id="pub.modal_id"
                  style="display: none"
                  v-on:click="hideModal(pub.modal_id)"
                >
                  <div class="modal-content" onclick="event.stopPropagation();">
                    <pre class="bibtex">{{ pub.bibtext }}</pre>
                  </div>
                </div>
                <button
                  class="btn btn-primary paper-button"
                  v-bind:data-clipboard-text="pub.bibtext"
                  title="Copy BibTex to Clipboard"
                >
                  <i class="far fa-copy"></i>
                </button>
                <a
                  v-if="pub.code"
                  class="btn btn-primary paper-button"
                  v-bind:href="pub.code"
                  >Code</a
                >
              </div>
            </div>
          </template>
        </div>
      </div>
    </section>

    <!-- Presentations section -->
    <section id="presentations" class="bg-light">
      <div class="container">
        <div class="row">
          <div class="col-lg-12 text-center">
            <h2 class="section-heading">Presentations</h2>
          </div>
        </div>
        <!-- <div class="row equal"> -->
        <!--   <div class="col-sm-2 talk-image hidden-sm hidden-md"> -->
        <!--     <img src="" class="img-thumbnail center-block" /> -->
        <!--   </div> -->
        <!--   <div class="col-lg-10"> -->
        <!--     <h3 class="talk-title">Talk Title</h3> -->
        <!--     <h4 class="talk-location">Talk Location</h4> -->
        <!--     <p class="text-muted">Talk Date</p> -->
        <!--     <p class="text-muted"> -->
        <!--       Talk content -->
        <!--     </p> -->
        <!--          <a href="">slides</a> -->
        <!--          <a href="">video</a> -->
        <!--   </div> -->
        <!-- </div> -->
        <div class="row equal">
          <div class="col-sm-2 talk-image hidden-sm hidden-md">
            <img
              src="static/img/presentations/neurips.png"
              class="img-thumbnail center-block"
            />
          </div>
          <div class="col-lg-10">
            <h3 class="talk-title">NeurIPS Spotlight Talk on Mead-Baseline</h3>
            <h4 class="talk-location">NeurIPS OSS Workshop</h4>
            <p class="text-muted">December 2018</p>
            <p class="text-muted">
              A spotlight talk, at the Open Source Software workshop at NeurIPS
              2018, highlighting the advantages of using our open-source,
              model-building toolkit, Mead-Baseline, which provides high-level
              model abstractions, correct evaluation metrics, and fast runtimes.
              Mead-Baseline is the foundation of all Deep Learning work, in both
              research and production, at Interactions.
            </p>
            <a href="static/presentations/slides/MLOSS-NeurIPS-Baseline.pdf"
              >slides</a
            >
          </div>
        </div>

        <div class="row equal">
          <div class="col-sm-2 talk-image hidden-sm hidden-md">
            <img
              src="static/img/presentations/calibration.png"
              class="img-thumbnail center-block"
            />
          </div>
          <div class="col-lg-10">
            <h3 class="talk-title">
              How do I trust my Model? Confidence in the Confidence of Neural
              Networks
            </h3>
            <h4 class="talk-location">
              Eastern Michigan University Machine Learning Conference
            </h4>
            <p class="text-muted">
              March 2020<sup class="footnote text-muted">*</sup>
            </p>
            <p class="text-muted">
              In most settings, one trains a model and then evaluates it on some
              held out test set; however, there are some domains where one would
              rather have no answer than an uncertain one. For example, if you
              have a human in the loop you might want to send an example to the
              human to double check it rather than just using the label produced
              by the model. Confidence models allows one to make decisions about
              how much trust to put into a model's predictions.
            </p>
            <p class="text-muted">
              This talk outlines the idea of confidence modeling, techniques
              used to evaluate models that allow for the rejection of examples
              based on confidences, the difficulties of getting well calibrated
              posteriors from Deep Learning models, and a summary of current
              work—using calibration techniques and auxiliary models—to produce
              high-fidelity confidence scores in the Natural Language
              Understanding module of a real world Dialogue System.
            </p>
            <sub class="footnote text-muted"
              ><sup class="text-muted">*</sup>Cancelled due to COVID-19</sub
            >
            <!-- <a href="">slides</a> -->
            <!-- <a href="">video</a> -->
          </div>
        </div>

        <div class="row equal">
          <div class="col-sm-2 talk-image hidden-sm hidden-md">
            <img
              src="static/img/presentations/masking.png"
              class="img-thumbnail center-block"
            />
          </div>
          <div class="col-lg-10">
            <h3 class="talk-title">
              Your Neural Network for Natural Language Processing is Probably
              Wrong
            </h3>
            <h4 class="talk-location">A2D-NLP</h4>
            <p class="text-muted">February 2020</p>
            <p class="text-muted">
              To efficiently train Deep Learning models processing multiple
              examples at once—aka batching—is paramount. The rub is that in NLP
              data often have differing sizes. We rectify this by adding empty
              data to smaller examples to bring them up to size: a technique we
              call padding. Padding comes with its own set of problems; if you
              aren't careful, calculations will include your padding elements
              and produce incorrect results.
            </p>
            <p class="text-muted">
              In this practitioner focused talk we cover how to batch, pad, and
              mask a range of neural network layers common in NLP including
              operations that obviously require masking like mean pooling, token
              level losses, and attention; complex operations like the CRF
              forward algorithm and Viterbi decoding; and subtle operations that
              you might not expect to require masking such as max pooling
              following a 1D convolution.
            </p>
            <a
              href="https://github.com/blester125/A2D-NLP-Talk-Feb-27-2020/blob/master/Your-Neural-Network-Is-Probably-Wrong.pdf"
            >
              slides
            </a>
          </div>
        </div>

        <div class="row equal">
          <div class="col-sm-2 talk-image hidden-sm hidden-md">
            <img
              src="static/img/presentations/numpy-cython.png"
              class="img-thumbnail center-block"
            />
          </div>
          <div class="col-lg-10">
            <h3 class="talk-title">Crunching Numbers with NumPy and Cython</h3>
            <h4 class="talk-location">Michigan Python Meetup</h4>
            <p class="text-muted">January 2020</p>
            <p class="text-muted">
              Based on a recent thread in the Ann Arbor data science Slack, this
              talk walks through the collaborative optimization of some numeric
              code. Beginning with a correct but slow implementation in Python,
              we will work though a series of improvements using NumPy, the
              Swiss army knife of scientific computing in Python. This talk will
              introduce core NumPy concepts like broadcasting and vectorization,
              and will wrap-up with a bespoke implementation in Cython for a
              blisteringly fast solution that can scale up to 10s of thousands
              of points in just second compared to the multi-hour runtime of a
              pure python soltuion.
            </p>
            <a
              href="https://github.com/blester125/MIPy-Talk-Jan-2-2020/blob/master/slides/slides.pdf"
            >
              slides
            </a>
          </div>
        </div>

        <div class="row equal">
          <div class="col-sm-2 talk-image hidden-sm hidden-md">
            <img
              src="static/img/presentations/char-input.png"
              class="img-thumbnail center-block"
            />
          </div>
          <div class="col-lg-10">
            <h3 class="talk-title">
              Input Representations of Deep Neural Networks
            </h3>
            <h4 class="talk-location">PyData Ann Arbor</h4>
            <p class="text-muted">October 2017</p>
            <p class="text-muted">
              A talk on creating robust models via learned character
              compositional input representations based on bLSTMs to support an
              open vocabulary for Deep Neural Networks.
            </p>
            <a
              href="https://github.com/blester125/language_model/blob/master/PyDataLightningBrianLester.pdf"
            >
              slides
            </a>
            <a href="presentations/pydata-2017.html"> video </a>
          </div>
        </div>
      </div>
    </section>

    <!-- Skills section -->
    <section id="skills" class="bg-light-gray">
      <div class="container">
        <div class="row">
          <div class="col-lg-12 text-center">
            <h2 class="section-heading">Skills</h2>
            <h3 class="section-subheading text-muted">
              Skilled in Data Science, Software Engineering, and more.
            </h3>
          </div>
        </div>
        <div class="row text-center">
          <div class="col-md-3">
            <span class="fa-stack fa-4x">
              <i class="fa fa-circle fa-stack-2x text-primary"></i>
              <i class="fas fa-brain fa-inverse fa-stack-1x"></i>
            </span>
            <h4 class="service-heading">Deep and Machine Learning</h4>
            <p class="text-muted">
              Extensive experience in using Jax, Flax, TensorFlow, Pytorch, and
              Scikit-learn for ML, specifically NLP, applications.
            </p>
          </div>
          <div class="col-md-3">
            <span class="fa-stack fa-4x">
              <i class="fa fa-circle fa-stack-2x text-primary"></i>
              <i class="fas fa-server fa-stack-1x fa-inverse"></i>
            </span>
            <h4 class="service-heading">Cloud and Infrastructure</h4>
            <p class="text-muted">
              Deep Understanding of building and deploying applications with
              Kubernetes, Docker, Flux, Prometheus, Apache Nifi, MongoDB, GitLab
              CI/CD, and GitHub actions
            </p>
          </div>
          <div class="col-md-3">
            <span class="fa-stack fa-4x">
              <i class="fa fa-circle fa-stack-2x text-primary"></i>
              <i class="fas fa-flask fa-stack-1x fa-inverse"></i>
            </span>
            <h4 class="service-heading">Data Science</h4>
            <p class="text-muted">
              Experience with Data Science toolkits such as NumPy, Pandas,
              Faiss, Gensim, SpaCy, NLTK, SciPy, Seaborn, and Matplotlib
            </p>
          </div>
          <div class="col-md-3">
            <span class="fa-stack fa-4x">
              <i class="fa fa-circle fa-stack-2x text-primary"></i>
              <i class="fa fa-code fa-stack-1x fa-inverse"></i>
            </span>
            <h4 class="service-heading">Programming Languages</h4>
            <p class="text-muted">
              In-depth understanding of Python, Cython, Java, and C. Experience
              with Javascript, C++, HTML, and \(\rm \LaTeX \)
            </p>
          </div>
        </div>
      </div>
    </section>

    <!-- Projects Section -->
    <section id="projects">
      <div class="container">
        <div class="row">
          <div class="col-lg-12 text-center">
            <h2 class="section-heading">Projects</h2>
            <h3 class="section-subheading text-muted">
              See more of my work on
              <a href="https://www.github.com/blester125">GitHub</a>
              .
            </h3>
          </div>
        </div>
        <!-- <a href="", class="project-link"> -->
        <!-- <div class="row equal"> -->
        <!--     <div class="col-lg-10"> -->
        <!--         <div class="row"> -->
        <!--             <div class="col-lg-10"> -->
        <!--                 <h3 class="project-title"> -->
        <!--                     Project Title -->
        <!--                 </h3> -->
        <!--             </div> -->
        <!--             <div class="col-lg-2"> -->
        <!--                 <h6 class="project-type"> -->
        <!--                     Project Type -->
        <!--                 </h6> -->
        <!--             </div> -->
        <!--         </div> -->
        <!--         <div class="row"> -->
        <!--             <div class="col-lg-10"></div> -->
        <!--             <div class="col-lg-2"> -->
        <!--                 <p class="project-date">Project Date</p> -->
        <!--             </div> -->
        <!--         </div> -->
        <!--         <p class="project-content"> -->
        <!--           Project Content -->
        <!--         </p> -->
        <!--     </div> -->
        <!--     <div class="col-lg-2 project-image hidden-sm hidden-md"> -->
        <!--         <img src="" class="img-thumbnail center-block" /> -->
        <!--     </div> -->
        <!-- </div> -->
        <!-- </a> -->

        <a
          href="https://github.com/dpressel/mead-baseline"
          ,
          class="project-link"
        >
          <div class="row equal">
            <div class="col-lg-10">
              <div class="row">
                <div class="col-lg-10">
                  <h3 class="project-title">Mead-Baseline</h3>
                </div>
                <div class="col-lg-2">
                  <h6 class="project-type">Open Source Library</h6>
                </div>
              </div>
              <div class="row">
                <div class="col-lg-10"></div>
                <div class="col-lg-2">
                  <p class="project-date">2018&ndash;Present</p>
                </div>
              </div>
              <p class="project-content">
                Core contributor to Mead-Baseline, a deep-learning toolkit for
                NLP that provids a uniform API to both tensorflow and pytorch
                backends, reusable implementations of complex neural
                architectures and layers, strong deep learning based models and
                good hyper-parameters, robust and correct evluation metrics, and
                performant batched implementations. Mead-Baseline uses Inversion
                of Control and an extensive plugin system to enable quick
                experiments by changing sections of model archetecutre with just
                a few lines of code. Model archetecture and training regime are
                specified in a configuration file to allow for repeatable
                research. Mead-Basline also enables easy access to a variety of
                contextual embeddings in the form of large pretrained language
                models like ELMo or BERT. Mead-Baseline also includes exporting
                utilities to convert models into either tensorflow serving
                servables or ONNX traced models which are ready to be deployed.
                Mead-Baseline is a one-stop shop that can take models all the
                way from prototyping to production.
              </p>
              <p class="project-content">
                My main work has been on the API design and implementation of
                the lower layers. I batched both the Conditional Random Field
                and the Beam Search yielding 6x speed ups. Before development on
                the framework basically stopped I created
                <a href="https://github.com/clab/dynet">DyNet</a>
                implementations of all the models in Mead-Baseline including
                large transformers. I introduced the ability to perform
                Constrained Decoding on the CRF where the rules of the
                transition scheme can be used to narrow down the number of
                possible transitions when doing Viterbi Decoding. Constrained
                Decoding gives gains across the board and should always be used.
              </p>
            </div>
            <div class="col-lg-2 project-image hidden-sm hidden-md">
              <img
                src="static/img/project/lstm.png"
                class="img-thumbnail center-block"
              />
            </div>
          </div>
        </a>

        <a href="https://github.com/blester125/iobes" , class="project-link">
          <div class="row equal">
            <div class="col-lg-10">
              <div class="row">
                <div class="col-lg-10">
                  <h3 class="project-title">IOBES</h3>
                </div>
                <div class="col-lg-2">
                  <h6 class="project-type">Open Source Library</h6>
                </div>
              </div>
              <div class="row">
                <div class="col-lg-10"></div>
                <div class="col-lg-2">
                  <p class="project-date">November 2020</p>
                </div>
              </div>
              <p class="project-content">
                A small library for parsing, converting, and manipulating span
                level NLP tasks (NER, slot-filling, etc) that are encoded as
                token level annotations like IOBES or BIO.
                <a href="https://www.aclweb.org/anthology/2020.nlposs-1.16/"
                  >A paper describing this library, and the need for
                  standardized tools for span level NLP, was published at the
                  second workshop on NLP Open Source Software.</a
                >
              </p>
            </div>
            <div class="col-lg-2 project-image hidden-sm hidden-md">
              <img
                src="static/img/project/iobes.png"
                class="img-thumbnail center-block"
              />
            </div>
          </div>
        </a>

        <a href="https://github.com/blester125/text-rank" class="project-link">
          <div class="row equal">
            <div class="col-lg-10">
              <div class="row">
                <div class="col-lg-10">
                  <h3 class="project-title">Text Rank</h3>
                </div>
                <div class="col-lg-2">
                  <h6 class="project-type">
                    Personal Project/Open Source Library
                  </h6>
                </div>
              </div>
              <div class="row">
                <div class="col-lg-10"></div>
                <div class="col-lg-2">
                  <p class="project-date"></p>
                </div>
              </div>
              <p class="project-content">
                An implementation of Text Rank in Python that reproduces the
                results from the original paper. I currently use it as a vehicle
                for personal research: investigating if deep learning based
                sentence similarities will yield better summaries. Results
                forthcoming.
              </p>
            </div>
            <div class="col-lg-2 project-image hidden-sm hidden-md">
              <img
                src="static/img/project/text-rank.png"
                class="img-thumbnail center-block"
              />
            </div>
          </div>
        </a>

        <a
          href="https://github.com/blester125/string-distance"
          class="project-link"
        >
          <div class="row equal">
            <div class="col-lg-10">
              <div class="row">
                <div class="col-lg-10">
                  <h3 class="project-title">String Distance</h3>
                </div>
                <div class="col-lg-2">
                  <h6 class="project-type">Open Source Library</h6>
                </div>
              </div>
              <div class="row">
                <div class="col-lg-10"></div>
                <div class="col-lg-2">
                  <p class="project-date"></p>
                </div>
              </div>
              <p class="project-content">
                A collection of various minimum edit distance algorithms as well
                as token based methods like Jaccard overlap. The algorithms are
                implemented in Cython and scale well. The library is able to
                compute minimum edit distances between entire Wikipedia pages in
                under asecond.
              </p>
            </div>
            <div class="col-lg-2 project-image hidden-sm hidden-md">
              <img
                src="static/img/project/string-dist.png"
                class="img-thumbnail center-block"
              />
            </div>
          </div>
        </a>

        <a href="https://github.com/blester125/quick_knn" class="project-link">
          <div class="row equal">
            <div class="col-lg-10">
              <div class="row">
                <div class="col-lg-10">
                  <h3 class="project-title">Quick KNN</h3>
                </div>
                <div class="col-lg-2">
                  <h6 class="project-type">Open Source Library</h6>
                </div>
              </div>
              <div class="row">
                <div class="col-lg-10"></div>
                <div class="col-lg-2">
                  <p class="project-date"></p>
                </div>
              </div>
              <p class="project-content">
                Implementations of Locality Sensitive Hashing. Supports using
                MinHash to approximate Jaccard similarity and Random Hyperplanes
                for a cosine based LSH. Also provides utilties to estimate
                optimal band size for some desired threshold of similarity. This
                library enables users to find similar items in very large
                corpora quickly.
              </p>
            </div>
            <div class="col-lg-2 project-image hidden-sm hidden-md">
              <img
                src="static/img/project/random-hyperplanes.png"
                class="img-thumbnail center-block"
              />
            </div>
          </div>
        </a>

        <div class="row equal">
          <div class="col-lg-10">
            <div class="row">
              <div class="col-lg-10">
                <h3 class="project-title">Dependency Parsing</h3>
              </div>
              <div class="col-lg-2">
                <h6 class="project-type">Personal Project</h6>
              </div>
            </div>
            <div class="row">
              <div class="col-lg-10"></div>
              <div class="col-lg-2">
                <p class="project-date"></p>
              </div>
            </div>
            <p class="project-content">
              Dependency parsing via Deep Learning models written in PyTorch.
              Supports training parsers via dynamic oracles using either the Arc
              Eager or the Arc Hybrid transition scheme or a Graph based parser
              using Biaffine Attention. Currently working on creating a shared
              interface between the two parser types with plans to release it as
              an open source library
            </p>
          </div>
          <div class="col-lg-2 project-image hidden-sm hidden-md">
            <img
              src="static/img/project/dep-parse.webp"
              class="img-thumbnail center-block"
            />
          </div>
        </div>

        <div class="row equal">
          <div class="col-lg-10">
            <div class="row">
              <div class="col-lg-10">
                <h3 class="project-title">PyPI Packages</h3>
              </div>
              <div class="col-lg-2">
                <h6 class="project-type">Open Source Libraries</h6>
              </div>
            </div>
            <div class="row">
              <div class="col-lg-10"></div>
              <div class="col-lg-2">
                <p class="project-date"></p>
              </div>
            </div>
            <p class="project-content">
              I have a collection of libraries hosted on PyPI, most enable
              narrow data science verticals but some are generic utilities.
            </p>
            <ul class="project-list">
              <li>
                <a href="https://pypi.org/project/file-or-name/">
                  file-or-name
                </a>
                <p class="pypi-description">
                  A decorator that lets you mark a function parameter as a file.
                  This will automatically open the file when the function is
                  called. This lets you write easy to test function that assume
                  pre-opened files but allows your users to pass in file paths
                  as strings.
                </p>
                <p class="pypi-description">
                  It also includes the ability to automatically do shadow paging
                  by pre-pending a write mode file with a <code>s</code>. This
                  is done by proxying all the writes to a temporary file and
                  then when you close the context manager the file was opened in
                  the original file is replaced with the temporary file. This
                  allows for atomic writes.
                </p>
              </li>
              <li>
                <a href="https://pypi.org/project/word-vectors/">
                  word-vectors
                </a>
                <p class="pypi-description">
                  Utilities to read and write common word vector formats such as
                  word2vec and glove. Also introduces a new format called Leader
                  which is a binary format like word2vec but we prefix the word
                  with its length. This allows for reading without having to
                  iterate over characters like word2vec does at the cost of just
                  3 bytes of disk space per word. Our benchmarks show this
                  format is faster for all common pre-trained embeddings.
                  <a href="https://arxiv.org/abs/2009.13699">
                    A paper describing the new embedding format, benchmarks
                    done, and the library can be found here.</a
                  >
                </p>
              </li>
              <li>
                <a href="https://pypi.org/project/inverted-index/">
                  inverted-index
                </a>
                <p class="pypi-description">
                  A small, extensible, in-memory inverted index to quickly added
                  full text search to a script. It also includes a
                  <code>prompt_toolkit</code> completer that will search the
                  inverted index as you type. Selecting an option will replace
                  the input with that value. This is useful for when there are a
                  lot of options to choose from and you want to provide a fuzzy
                  search when looking for the right one.
                </p>
              </li>
              <li>
                <a href="https://pypi.org/project/get-mnist/">get-mnist</a>
                <p class="pypi-description">
                  Lightweight utilities to download and load both the MNIST and
                  Fashion MNIST datasets. The only dependency is NumPy.
                </p>
              </li>
              <li>
                <a href="https://pypi.org/project/search-cli/">search-cli</a>
                <p class="pypi-description">
                  A GUI around surfraw that lets you open a search box from
                  anywhere, it also lets you do a search where the query is
                  whatever text is highlighted.
                </p>
              </li>
              <li>
                <a href="https://pypi.org/project/prehashed/">prehashed</a>
                <p class="pypi-description">
                  A dictionary subclass that stores the sha1 hash of keys rather
                  than the full key. This reduces storage space, for example if
                  your keys are long documents you can store and retrieve stats
                  about them without storing the whole document in memory.
                </p>
              </li>
              <li>
                <a href="https://pypi.org/project/true-case/">true-case</a>
                <p class="pypi-description">
                  An interface that gives the probability that a token should be
                  capitalized. Probabilities were estimated from the
                  CNN/DailyMail dataset.
                </p>
              </li>
              <li>
                <a href="https://pypi.org/project/quick-knn/">quick-knn</a>
                <p class="pypi-description">
                  An LSH implementation that supports Jaccard Similarity through
                  MinHash and cosine similarity via Random Hyperplanes.
                </p>
              </li>
              <li>
                <a href="https://pypi.org/project/string-distance/">
                  string-distance
                </a>
                <p class="pypi-description">
                  Cython implementations of various string distance algorithms.
                </p>
              </li>
              <li>
                <a href="https://pypi.org/project/delta-of-delta/">
                  delta-of-delta
                </a>
                <p class="pypi-description">
                  Pedagogical implementations of various time-stamp encoding
                  algorithms.
                </p>
              </li>
            </ul>
          </div>
          <div class="col-lg-2 project-image hidden-sm hidden-md">
            <img
              src="static/img/project/pypi.png"
              class="img-thumbnail center-block"
            />
          </div>
        </div>

        <a
          href="https://github.com/blester125/Decomposable_Attention"
          class="project-link"
        >
          <div class="row equal">
            <div class="col-lg-10">
              <div class="row">
                <div class="col-lg-10">
                  <h3 class="project-title">Decomposable Attention</h3>
                </div>
                <div class="col-lg-2">
                  <h6 class="project-type">Personal Project</h6>
                </div>
              </div>
              <div class="row">
                <div class="col-lg-10"></div>
                <div class="col-lg-2">
                  <p class="project-date">Winter 2017</p>
                </div>
              </div>
              <p class="project-content">
                A reimplementation of the paper
                <a href="https://arxiv.org/abs/1606.01933">
                  “A Decomposable Attention Model for Natural Language
                  Inference”
                </a>
                in DyNet. I was able to reproduce the paper results via
                extensive hyper parameter tuning
              </p>
            </div>
            <div class="col-lg-2 project-image hidden-sm hidden-md">
              <img
                src="static/img/project/attention.png"
                class="img-thumbnail center-block"
              />
            </div>
          </div>
        </a>

        <a
          href="https://github.com/blester125/Self_Driving_Network"
          class="project-link"
        >
          <div class="row equal">
            <div class="col-lg-10">
              <div class="row">
                <div class="col-lg-10">
                  <h3 class="project-title">Steering Angles</h3>
                </div>
                <div class="col-lg-2">
                  <h6 class="project-type">Personal Project</h6>
                </div>
              </div>
              <div class="row">
                <div class="col-lg-10"></div>
                <div class="col-lg-2">
                  <p class="project-date">Fall 2016</p>
                </div>
              </div>
              <p class="project-content">
                Using a deep convolutional network steering angles are predicted
                from a front facing camera. The network is 20 layers deep and
                uses various network architecture modifications to decrease
                training times. These include residual connections and batch
                normalization.
              </p>
            </div>
            <div class="col-lg-2 project-image hidden-sm hidden-md">
              <img
                src="static/img/project/drive.gif"
                class="img-thumbnail center-block"
              />
            </div>
          </div>
        </a>

        <a
          href="https://github.com/blester125/multi_digit_recognition"
          class="project-link"
        >
          <div class="row equal">
            <div class="col-lg-10">
              <div class="row">
                <div class="col-lg-10">
                  <h3 class="project-title">Multi-Digit Recognition</h3>
                </div>
                <div class="col-lg-2">
                  <h6 class="project-type">Personal Project</h6>
                </div>
              </div>
              <div class="row">
                <div class="col-lg-10"></div>
                <div class="col-lg-2">
                  <p class="project-date">Summer 2016</p>
                </div>
              </div>
              <p class="project-content">
                Using a deep convolutional network, written in Tensorflow,
                multi-digit sequences (up to five digits) are classified. This
                is done using an end-to-end network that recognize the digits in
                one step rather than creating separate parts that localize the
                digits, segment them, and then classify each digit individually.
                This network was trained using the Stanford Street View House
                Numbers Dataset and achieves 93.89 percent accuracy on the test
                dataset. Read the full write up
                <a
                  href="https://github.com/blester125/multi_digit_recognition/blob/master/Report.pdf"
                >
                  here
                </a>
              </p>
            </div>
            <div class="col-lg-2 project-image hidden-sm hidden-md">
              <img
                src="static/img/project/digits.png"
                class="img-thumbnail center-block"
              />
            </div>
          </div>
        </a>

        <a
          href="https://github.com/blester125/TCP-with-Minet"
          class="project-link"
        >
          <div class="row equal">
            <div class="col-lg-10">
              <div class="row">
                <div class="col-lg-10">
                  <h3 class="project-title">
                    RFC 793 Transmission Control Protocol
                  </h3>
                </div>
                <div class="col-lg-2">
                  <h6 class="project-type">University of Pittsburgh</h6>
                </div>
              </div>
              <div class="row">
                <div class="col-lg-10"></div>
                <div class="col-lg-2">
                  <p class="project-date">Fall 2015</p>
                </div>
              </div>
              <p class="project-content">
                Implementation of the Transmission Control Protocol (RFC 793)
                completed for Data Communications and Computer Networking. This
                implementation is fully functional TCP implementation required
                to ensure both packet delivery as well as in-order delivery of
                packets. This implementation also supports multiple in flight
                packets with using the "Go Back N" strategy. This requires the
                Minet framework to function.
              </p>
            </div>
            <div class="col-lg-2 project-image hidden-sm hidden-md">
              <img
                src="static/img/project/tcp-ascii.png"
                class="img-thumbnail center-block"
              />
            </div>
          </div>
        </a>

        <a href="https://github.com/blester125/CS_1645" class="project-link">
          <div class="row equal">
            <div class="col-lg-10">
              <div class="row">
                <div class="col-lg-10">
                  <h3 class="project-title">Particle Simulation</h3>
                </div>
                <div class="col-lg-2">
                  <h6 class="project-type">University of Pittsburgh</h6>
                </div>
              </div>
              <div class="row">
                <div class="col-lg-10"></div>
                <div class="col-lg-2">
                  <p class="project-date">Spring 2015</p>
                </div>
              </div>
              <p class="project-content">
                Particle interaction simulation written in C++. This simulation
                was written for parallel computation using the Message Passing
                Interface (MPI) and run on the Stampede super computer at Texas
                Advanced Computing Center. The simulation was carried out using
                the Ring Algorithm. Analysis of the program showed linear speed
                up as the number of processors was increased.
              </p>
            </div>
            <div class="col-lg-2 project-image hidden-sm hidden-md">
              <img
                src="static/img/project/hpc.jpg"
                class="img-thumbnail center-block"
              />
            </div>
          </div>
        </a>

        <a
          href="https://github.com/blester125/Secure-File-Sharing"
          class="project-link"
        >
          <div class="row equal">
            <div class="col-lg-10">
              <div class="row">
                <div class="col-lg-10">
                  <h3 class="project-title">Secure File Sharing System</h3>
                </div>
                <div class="col-lg-2">
                  <h6 class="project-type">University of Pittsburgh</h6>
                </div>
              </div>
              <div class="row">
                <div class="col-lg-10"></div>
                <div class="col-lg-2">
                  <p class="project-date">Spring: 2016</p>
                </div>
              </div>
              <p class="project-content">
                Distributed group-based file sharing system written in Java.
                This includes a multi-threaded group server that handles user
                authentication and distributes token to users. Multi-threaded
                file servers use the tokens to distribute files only to approved
                users. A GUI for clients to access files was also created. This
                Systems is secure as well. Cryptographic tools like symmetric
                and public key cryptography, Diffie Hellman key exchange and
                digital signatures are leverage to create secure authentication
                protocols that provide perfect forward security, repel man in
                the middle attacks, and provide plausible deniability. This
                system uses two-factor authentication via a Time based One Time
                Password (TOTP) scheme as outlined in RFC 6238.
              </p>
            </div>
            <div class="col-lg-2 project-image hidden-sm hidden-md">
              <img
                src="static/img/project/crypto.png"
                class="img-thumbnail center-block"
              />
            </div>
          </div>
        </a>

        <a
          href="https://github.com/blester125/facial_recognition"
          class="project-link"
        >
          <div class="row equal">
            <div class="col-lg-10">
              <div class="row">
                <div class="col-lg-10">
                  <h3 class="project-title">
                    Face Detection and Classification
                  </h3>
                </div>
                <div class="col-lg-2">
                  <h6 class="project-type">Personal Project</h6>
                </div>
              </div>
              <div class="row">
                <div class="col-lg-10"></div>
                <div class="col-lg-2">
                  <p class="project-date">Summer 2016</p>
                </div>
              </div>
              <p class="project-content">
                Facial detection and recognition in video streams. Facial
                detection is done with dlib's CUDA accelerated histogram of
                ordered gradients frontal face detector to find faces and then
                dlib again to estimate facial landmarks. These landmarks are
                then transformed using an affine transformation in openCV to
                center the face in the image. Embeddings are then generated
                using a deep neural network written in torch from the OpenFace
                project at Carnegie Mellon University. These embeddings are can
                then be classified by various machine learning techniques. This
                project used a support vector machine from Scikit-learn to
                classify the faces in the image.
              </p>
            </div>
            <div class="col-lg-2 project-image hidden-sm hidden-md">
              <img
                src="static/img/project/face.png"
                class="img-thumbnail center-block"
              />
            </div>
          </div>
        </a>

        <a
          href="https://github.com/blester125/CS_1622_Compilers"
          class="project-link"
        >
          <div class="row equal">
            <div class="col-lg-10">
              <div class="row">
                <div class="col-lg-10">
                  <h3 class="project-title">Compiler</h3>
                </div>
                <div class="col-lg-2">
                  <h6 class="project-type">University of Pittsburgh</h6>
                </div>
              </div>
              <div class="row">
                <div class="col-lg-10"></div>
                <div class="col-lg-2">
                  <p class="project-date">Spring 2016</p>
                </div>
              </div>
              <p class="project-content">
                A compiler written in C to compile an Object-Oriented language
                called MINI-Java. Lexical analysis is done using code generated
                by Lex based on specified regular expressions. Syntax analysis
                is done using a Context Free Grammar and Yacc. This syntactic
                analysis produces an Abstract Syntax Tree that is then parsed in
                the Semantic analysis phase.
                <!-- The code generation phase will produce assembly code targeted at the MIPS architecture. -->
              </p>
            </div>
            <div class="col-sm-2 project-image hidden-sm hidden-md">
              <img
                src="static/img/project/compiler.png"
                class="img-thumbnail center-block"
              />
            </div>
          </div>
        </a>

        <a
          href="https://github.com/blester125/Kasiski_Examination"
          ,
          class="project-link"
        >
          <div class="row equal">
            <div class="col-lg-10">
              <div class="row">
                <div class="col-lg-10">
                  <h3 class="project-title">
                    Code Breaking with Kasiski Examination
                  </h3>
                </div>
                <div class="col-lg-2">
                  <h6 class="project-type">University of Pittsburgh</h6>
                </div>
              </div>
              <div class="row">
                <div class="col-lg-10"></div>
                <div class="col-lg-2">
                  <p class="project-date">Spring 2016</p>
                </div>
              </div>
              <p class="project-content">
                A simple program for breaking Vigenere Ciphers for homework 2 of
                CS 1653 at the University of Pittsburgh. This program works by
                tracking the distances between sets of repeating characters to
                try to estimate the length of the key. I didn't have time to
                implement frequency analysis to try to figure out what the key
                actually was. This program is written in C and includes a C
                implementaion of a Red-Black tree (used to track the offsets
                between repeating sequences of characters).
              </p>
            </div>
            <div class="col-lg-2 project-image hidden-sm hidden-md">
              <img
                src="static/img/project/red-black-tree.png"
                class="img-thumbnail center-block"
              />
            </div>
          </div>
        </a>

        <a
          href="https://github.com/blester125/LeagueMakers"
          ,
          class="project-link"
        >
          <div class="row equal">
            <div class="col-lg-10">
              <div class="row">
                <div class="col-lg-10">
                  <h3 class="project-title">League Maker</h3>
                </div>
                <div class="col-lg-2">
                  <h6 class="project-type">University of Pittsburgh</h6>
                </div>
              </div>
              <div class="row">
                <div class="col-lg-10"></div>
                <div class="col-lg-2">
                  <p class="project-date">Spring 2015</p>
                </div>
              </div>
              <p class="project-content">
                A web app that allows users to create a league, schedule
                matches, report and track results, and rank participants using
                the Elo ranking system. Once league rankings have been
                established integration with challonge allow users to run
                tournaments that are automatically seeded based on the Elo
                ranking of the players. This was created for CS 1520 in
                collaboration with Chris Price, David Robertson, and Troy
                Taylor. The app is written and deployed with Google App Engine.
                A live demo is found
                <a href="https://leaguemakers.appspot.com">here</a>.
              </p>
            </div>
            <div class="col-lg-2 project-image hidden-sm hidden-md">
              <img
                src="static/img/project/league-maker-bracket.png"
                class="img-thumbnail center-block"
              />
            </div>
          </div>
        </a>
      </div>
    </section>

    <!-- Blog Section -->
    <section id="blog" class="bg-light-gray">
      <div class="container">
        <div class="row">
          <div class="col-lg-12 text-center">
            <h2 class="section-heading">Blog</h2>
            <h3 class="section-subheading text-muted">
              A collection of blog posts, mostly about how the math of machine
              learning works.
            </h3>
          </div>
        </div>

        <div id="blog-container">
          <template v-for="blog in blogs">
            <div class="row">
              <div class="col-lg-8 col-lg-offset-2">
                <h3 class="blog-title">{{ blog.title }}</h3>
                <div class="row">
                  <div class="col-lg-2">
                    <p class="text-muted">{{ blog.date }}</p>
                  </div>
                  <div class="col-lg-10">
                    <span class="blog-tags">
                      <i class="fas fa-tags"></i>
                      <span v-for="(tag, index) in blog.tags">
                        <a
                          class="tag"
                          :href="tag.link"
                          v-if="index != blog.tags.length - 1"
                          >{{ tag.name }},
                        </a>
                        <a class="tag" :href="tag.link" v-else
                          >{{ tag.name }}</a
                        >
                      </span>
                    </span>
                  </div>
                </div>
                <div class="row col-lg-12">
                  <p class="text-muted">{{ blog.description }}</p>
                </div>
                <div class="row col-lg-12">
                  <a class="btn btn-primary btn-outline" :href="blog.link"
                    >Continue Reading</a
                  >
                </div>
              </div>
            </div>
          </template>
        </div>
      </div>
    </section>

    <!-- Education Section -->
    <section id="education">
      <div class="container">
        <div class="row col-lg-12 text-center">
          <h2 class="section-heading">Education</h2>
          <h3 class="section-subheading text-muted">
            The University of Pittsburgh
          </h3>
        </div>
        <div class="row text-center">
          <div class="col-md-4">
            <span class="fa-stack fa-4x">
              <i class="fa fa-circle fa-stack-2x text-primary"></i>
              <i class="fa fa-university fa-stack-1x fa-inverse"></i>
            </span>
            <h4 class="service-heading">Degrees</h4>
            <p class="text-muted" style="text-align: left">
              Double Major at the University of Pittsburgh.
              <br />
              Bachelor of Science in Computer Science with honors.
              <br />
              Bachelor of Science in Neuroscience.
            </p>
          </div>
          <div class="col-md-4">
            <span class="fa-stack fa-4x">
              <i class="fa fa-circle fa-stack-2x text-primary"></i>
              <i class="fas fa-pencil-alt fa-stack-1x fa-inverse"></i>
            </span>
            <h4 class="service-heading">Significant Courses</h4>
            <p class="text-muted" style="text-align: left">
              Data Communications and Computer Networks
              <br />
              High Performance Computing
              <br />
              Algorithm Design
              <br />
              Applied Cryptography and Network Security
              <br />
              Compiler Design
              <br />
              Programming Languages for Web Applications
              <br />
              Software Quality Assurance
              <br />
            </p>
          </div>
          <div class="col-md-4">
            <span class="fa-stack fa-4x">
              <i class="fa fa-circle fa-stack-2x text-primary"></i>
              <i class="fa fa-laptop fa-stack-1x fa-inverse"></i>
            </span>
            <h4 class="service-heading">Continuous Learning</h4>
            <p class="text-muted" style="text-align: left">
              Audit lectures and completed assignments for many online courses
              including, Coursea Machine Learning, Udacity Machine Learning
              Nanodegree, Stanford CS 224n Deep Learning for Natural Language
              Processing, and CS 11-747 Neural Networks for NLP from Carnegie
              Mellon.
            </p>
          </div>
        </div>
      </div>
    </section>

    <div id="footer"></div>
  </body>
</html>
