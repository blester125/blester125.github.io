<!DOCTYPE html>
<html lang="en">
  <head>
    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script
      async
      src="https://www.googletagmanager.com/gtag/js?id=UA-156541294-1"
    ></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag() {
        dataLayer.push(arguments);
      }
      gtag("js", new Date());
      gtag("config", "UA-156541294-1");
    </script>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="description" content="A site that catalogs what I have done." />
    <meta name="author" content="Brian Lester" />

    <title>Brian Lester</title>

    <!-- Bootstrap Core CSS -->
    <link rel="stylesheet" href="static/css/bootstrap.css" />

    <!-- Third Party CSS -->
    <link rel="stylesheet" href="static/css/agency.css" />
    <link rel="stylesheet" href="static/css/academicons.min.css" />

    <!-- Custom CSS -->
    <link href="static/css/latex.css" rel="stylesheet" />
    <link href="static/css/presentation.css" rel="stylesheet" />
    <link href="static/css/paper.css" rel="stylesheet" />
    <link href="static/css/project.css" rel="stylesheet" />
    <link href="static/css/nav.css" rel="stylesheet" />
    <link href="static/css/blog.css" rel="stylesheet" />
    <link href="static/css/experience.css" rel="stylesheet" />

    <!-- Custom Fonts -->
    <link href="static/css/all.min.css" rel="stylesheet" type="text/css" />
    <link
      href="https://fonts.googleapis.com/css?family=Montserrat:400,700"
      rel="stylesheet"
      type="text/css"
    />
    <link
      href="https://fonts.googleapis.com/css?family=Kaushan+Script"
      rel="stylesheet"
      type="text/css"
    />
    <link
      href="https://fonts.googleapis.com/css?family=Droid+Serif:400,700,400italic,700italic"
      rel="stylesheet"
      type="text/css"
    />
    <link
      href="https://fonts.googleapis.com/css?family=Roboto+Slab:400,100,300,700"
      rel="stylesheet"
      type="text/css"
    />

    <!-- HTML5 Shim and Respond.js IE8 support of HTML5 elements and media queries -->
    <!-- WARNING: Respond.js doesn't work if you view the page via file:// -->
    <!--[if lt IE 9]>
      <script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
      <script src="https://oss.maxcdn.com/libs/respond.js/1.4.2/respond.min.js"></script>
    <![endif]-->

    <!-- favicon the logo in the tab -->
    <link rel="icon" href="static/img/favicon.ico" type="image/x-icon" />
    <link
      rel="shortcut icon"
      href="static/img/favicon.ico"
      type="image/x-icon"
    />

    <!-- jQuery -->
    <script src="static/js/jquery.js"></script>
    <!-- Bootstrap Core JavaScript -->
    <script src="static/js/bootstrap.min.js"></script>
    <!-- Plugin JavaScript -->
    <script src="static/js/jquery.easing.min.js"></script>
    <script src="static/js/agency.js"></script>
    <!-- Generate the publications section from by bib file -->
    <script src="static/js/citation-0.4.0-9.js" type="text/javascript"></script>
    <script src="static/js/clipboard.min.js" type="text/javascript"></script>
    <script src="static/js/references.js"></script>
    <script>
      readFile(
        "static/references/index.txt",
        generate_references.bind(
          null,
          "publications-container",
          "static/references/"
        )
      );
    </script>
  </head>

  <body id="page-top" class="index">
    <!-- Navigation -->
    <nav class="navbar navbar-default navbar-fixed-top navbar-shrink">
      <div class="container">
        <!-- Brand and toggle get grouped for better mobile display -->
        <div class="navbar-header page-scroll">
          <button
            type="button"
            class="navbar-toggle collapsed"
            data-toggle="collapse"
            data-target="#bs-example-navbar-collapse-1"
          >
            <span class="sr-only">Toggle navigation</span>
            <i class="fas fa-bars fa-1x"></i>
          </button>
          <a class="navbar-brand page-scroll" href="#page-top">Brian Lester</a>
        </div>

        <!-- Collect the nav links, forms, and other content for toggling -->
        <div class="collapse navbar-collapse" id="bs-example-navbar-collapse-1">
          <ul class="nav navbar-nav navbar-right">
            <li class="hidden">
              <a href="#page-top"></a>
            </li>
            <li>
              <a class="page-scroll" href="static/resume/BrianLesterCV.pdf">
                Resume
              </a>
            </li>
            <li>
              <a class="page-scroll" href="#blog">Blog</a>
            </li>
            <li>
              <a class="page-scroll" href="#experience">Experience</a>
            </li>
            <li>
              <a class="page-scroll" href="#skills">Skills</a>
            </li>
            <li>
              <a class="page-scroll" href="#projects">Projects</a>
            </li>
            <li>
              <a class="page-scroll" href="#presentations">Presentations</a>
            </li>
            <li>
              <a class="page-scroll" href="#publications">Publications</a>
            </li>
            <li>
              <a class="page-scroll" href="#education">Education</a>
            </li>
          </ul>
        </div>
        <!-- /.navbar-collapse -->
      </div>
      <!-- /.container-fluid -->
    </nav>

    <!-- Header -->
    <header>
      <div class="container">
        <div class="intro-text">
          <div class="team-member">
            <img
              src="static/img/team/BrianLester.jpg"
              class="img-responsive img-circle"
              alt=""
            />
          </div>
          <div class="intro-heading">Brian Lester</div>
          <div class="team-member">
            <!-- This should match the bottom buttons -->
            <ul class="list-inline social-buttons">
              <li>
                <a href="https://twitter.com/blester125">
                  <i class="fab fa-twitter"></i>
                </a>
              </li>

              <li>
                <a href="https://www.linkedin.com/in/blester125">
                  <i class="fab fa-linkedin"></i>
                </a>
              </li>
              <li>
                <a
                  href="https://scholar.google.com/citations?user=OWSQqZMAAAAJ&hl=en"
                >
                  <i class="ai ai-google-scholar"></i>
                </a>
              </li>

              <li>
                <a href="https://pypi.org/user/BLester125/">
                  <i class="fab fa-python"></i>
                </a>
              </li>
              <li>
                <a href="https://github.com/blester125">
                  <i class="fab fa-github"></i>
                </a>
              </li>
            </ul>
          </div>
        </div>
      </div>
    </header>

    <!-- Blog Section -->
    <section id="blog" class="bg-light-gray">
      <div class="container">
        <div class="row">
          <div class="col-lg-12 text-center">
            <h2 class="section-heading">Blog</h2>
            <h3 class="section-subheading text-muted">
              A collection of blog posts, mostly about how the math of machine
              learning works.
            </h3>
          </div>
        </div>

        <!-- <div class="row"> -->
        <!--   <div class="col-lg-8 col-lg-offset-2"> -->
        <!--     <h3> -->
        <!--       Blog Title -->
        <!--     </h3> -->
        <!--     <div class="row"> -->
        <!--       <div class="col-lg-2"> -->
        <!--         <p class="text-muted">Blog Date</p> -->
        <!--       </div> -->
        <!--       <div class="col-lg-10"> -->
        <!--         <span class="blog-tags"> -->
        <!--           <i class="fas fa-tags"></i> -->
        <!--           <a class="tag">Tag1,</a> -->
        <!--           <a class="tag">Tag2,</a> -->
        <!--           <a class="tag">...</a> -->
        <!--         </span> -->
        <!--       </div> -->
        <!--     </div> -->
        <!--     <div class="row col-lg-12"> -->
        <!--       <p class="text-muted"> -->
        <!--         blog summary -->
        <!--       </p> -->
        <!--     </div> -->
        <!--     <div class="row col-lg-12"> -->
        <!--       <a class="btn btn-primary btn-outline" href="BLOG-LINK" -->
        <!--         >Continue Reading</a -->
        <!--       > -->
        <!--     </div> -->
        <!--   </div> -->
        <!-- </div> -->

        <div class="row">
          <div class="col-lg-8 col-lg-offset-2">
            <h3 class="blog-title">
              Numerically Stable Softmax
            </h3>
            <div class="row">
              <div class="col-lg-2">
                <p class="text-muted">February, 2020</p>
              </div>
              <div class="col-lg-10">
                <span class="blog-tags">
                  <i class="fas fa-tags"></i>
                  <a class="tag">neural networks,</a>
                  <a class="tag">implementation,</a>
                  <a class="tag">numerical stability</a>
                </span>
              </div>
            </div>
            <div class="row col-lg-12">
              <p class="text-muted">
                An explanation of the math behind the trick of subtracting the
                max value from the logits to calculate the softmax in a
                numerically stable way.
              </p>
            </div>
            <div class="row col-lg-12">
              <a class="btn btn-primary btn-outline" href="blog/softmax.html">
                Continue Reading
              </a>
            </div>
          </div>
        </div>

        <div class="row">
          <div class="col-lg-8 col-lg-offset-2">
            <h3 class="blog-title">
              Multiclass Matthew's Correlation Coefficient
            </h3>
            <div class="row">
              <div class="col-lg-2">
                <p class="text-muted">January, 2020</p>
              </div>
              <div class="col-lg-10">
                <span class="blog-tags">
                  <i class="fas fa-tags"></i>
                  <a class="tag">metrics,</a>
                  <a class="tag">implementation</a>
                </span>
              </div>
            </div>
            <div class="row col-lg-12">
              <p class="text-muted">
                An explanation of how the rather opaque vectorized
                implementations of Multiclass Matthew's Correlation Coefficient
                found in popular open-source, machine learning libraries work.
              </p>
            </div>
            <div class="row col-lg-12">
              <a class="btn btn-primary btn-outline" href="blog/rk.html">
                Continue Reading
              </a>
            </div>
          </div>
        </div>
      </div>
    </section>

    <!-- Experience Section -->
    <section id="experience">
      <div class="container">
        <div class="row">
          <div class="col-lg-12 text-center">
            <h2 class="section-heading">Experience</h2>
            <h3 class="section-subheading text-muted">Work History</h3>
          </div>
        </div>
        <div class="row">
          <div class="col-lg-12">
            <ul class="timeline">
              <!-- Begin Interactions -->
              <li>
                <div class="timeline-image">
                  <img
                    class="img-circle img-responsive"
                    src="static/img/experience/interactions.png"
                  />
                </div>
                <div class="timeline-panel">
                  <div class="timeline-heading">
                    <h4>Interactions</h4>
                    <h4 class="subheading">April 2018&#8211;Present</h4>
                  </div>
                  <div class="timeline-body">
                    <p class="text-muted job-left">
                      <strong>Machine Learning Engineer</strong>
                      &#8212;Specializing in using Deep Learning for Natural
                      Language Processing (NLP). Research into new effective
                      training methods and model architectures, building client
                      models for production, and creating infrastructure that
                      enables distributed, cloud-native, training and
                      horizontally scalalbe model serving.
                    </p>
                    <p class="text-muted job-left">
                      I maintain Mead-Baseline&#8212;our open-source
                      deep-learning toolkit. It is the go to path for all deep
                      learning work (research and production) within the
                      company. I have created performant implementations of
                      various complex neural network architectures including a
                      Conditional Random Field and Beam Search.
                    </p>
                    <p class="text-muted job-left">
                      Designed the label space and annotation guidelines for the
                      Natural Language Understanding module of a customer
                      self-service dialogue system in the technical support
                      domain. My design focused on general intents, complex
                      entities, and relations to cover diverse and complex
                      conversational domain.
                    </p>
                    <p class="text-muted job-left">
                      Created our cloud-native, deep-learning model training
                      platform. Out platform is a Directed Acyclic Graph (DAG)
                      engine powered by kubernetes that can execute any pipeline
                      of tasks that can be run inside of docker containers. Our
                      platform automatically parallelizes non dependent nodes in
                      the DAG (allowing for Hyper Parameter Optimization (HPO))
                      and can distribute a single step over multiple GPUs. Using
                      Kubernetes allows for effective sharing of cluster
                      resources among disjoint users. The platform enables
                      building mutli-step pipelines that can take a model from
                      raw training data to a model that is ready for production.
                    </p>
                    <p class="text-muted job-left">
                      Created and Maintain our deep-learning model serving
                      infrastructure. The server, backed by TensorFlow Serving,
                      enables rich Natural Language Understanding (NLU) via
                      cascading calls to a series of deep learning models. Both
                      the server itself and the TensorFlow Serving backend are
                      deployed via Kubernetes. This server is currently powering
                      NLU for several production dialogue systems.
                    </p>
                    <p class="text-muted job-left">
                      Created a wide range of Machine Learning models powering
                      client-facing production models. The architectures and
                      tasks range from ConvNets for classification (used in
                      intent detection), bLSTM-CRF taggers for general purpose
                      tagging (NER, POS, Chunking) and client-specific slot
                      filling, to Transformer-based seq2seq models used to
                      automatically suggest agent responses.
                    </p>
                  </div>
                </div>
              </li>
              <!-- Begin Trove -->
              <li class="timeline-inverted">
                <div class="timeline-image">
                  <img
                    class="img-circle img-responsive"
                    src="static/img/experience/trove.png"
                  />
                </div>
                <div class="timeline-panel">
                  <div class="timeline-heading">
                    <h4>Trove</h4>
                    <h4 class="subheading">March 2017&#8211;April 2018</h4>
                  </div>
                  <div class="timeline-body">
                    <p class="text-muted job-right">
                      <strong>Lead Machine Learning Research Engineer</strong>
                      &#8212;Used machine learning, natural language processing,
                      computer vision, and cutting edge deep neural networks to
                      power improve heuristic based existing features and create
                      new features. Designed and Implemented our model serving
                      infrastructure that processed 200 emails a day. Provided
                      technical leadership to the data science team.
                    </p>
                    <p class="text-muted job-right">
                      Trove would detect and surface sentences in emails that
                      warranted a response to help track emails that were
                      important to reply too. This was originally done via a
                      tangled mess of regular expressions. Using unsupervised
                      methods and iterative refinement I bootstrapped a dataset
                      of these sentences. Using a ConvNet I was able to create a
                      system better than the regex. The ConvNet was also able to
                      account for semantic meaning and we refined the product so
                      that it highlights requests that can be handled via email
                      not just any ask. The results of this model became a
                      staple feature in the annotated email social graph that
                      trove created.
                    </p>
                    <p class="text-muted job-right">
                      Used a neural ranking model to preform coreference
                      resolution by linking anaphors to their antecedents. By
                      replacing pronominal mentions in the question snippets
                      extracted from emails we were able to provide context to
                      the users.
                    </p>
                    <p class="text-muted job-right">
                      Used lexical features from the email as well as
                      connectivity information in the email social graph to
                      identify bot accounts. We used a broad definition of bots
                      to include things like newsletters and automated email
                      from things like github. We used these classification
                      labels to help filter search results.
                    </p>
                  </div>
                </div>
              </li>
              <!-- End Trove -->
              <!-- VISTEON -->
              <li>
                <div class="timeline-image">
                  <img
                    class="img-circle img-responsive"
                    src="static/img/experience/Visteon.png"
                  />
                </div>
                <div class="timeline-panel">
                  <div class="timeline-heading">
                    <h4>Visteon Corporation</h4>
                    <h4 class="subheading">May 2015&#8211;August 2015</h4>
                  </div>
                  <div class="timeline-body">
                    <p class="text-muted job-left">
                      <strong>Software Engineering Intern</strong>
                      &#8212;Specialized in Voice Recognition and User
                      Information Systems.
                    </p>
                    <p class="text-muted job-left">
                      Prototyped and Vetted Dragon Drive Link, an on-board
                      real-time driver information and entertainment application
                      similar to Android Auto.
                    </p>
                    <p class="text-muted job-left">
                      Research, designed, and implemented a system to optimize
                      Voice Recognition used in Production Mazda cars. It
                      dynamically decides if it should display a menu of
                      disambiguation options based on the users past
                      interactions with the system. We patented with system
                      <a
                        href="https://patents.google.com/patent/US9984688B2/en"
                      >
                        (US 9984688B2)
                      </a>
                    </p>
                  </div>
                </div>
              </li>
              <!-- End Visteon -->
            </ul>
          </div>
        </div>
      </div>
    </section>

    <!-- Skills section -->
    <section id="skills" class="bg-light-gray">
      <div class="container">
        <div class="row">
          <div class="col-lg-12 text-center">
            <h2 class="section-heading">Skills</h2>
            <h3 class="section-subheading text-muted">
              Skilled in Data Science, Software Engineering, and more.
            </h3>
          </div>
        </div>
        <div class="row text-center">
          <div class="col-md-3">
            <span class="fa-stack fa-4x">
              <i class="fa fa-circle fa-stack-2x text-primary"></i>
              <i class="fas fa-brain fa-inverse fa-stack-1x"></i>
            </span>
            <h4 class="service-heading">Deep and Machine Learning</h4>
            <p class="text-muted">
              Extensive experience in using Pytorch, TensorFlow, and
              Scikit-learn for NLP applications.
            </p>
          </div>
          <div class="col-md-3">
            <span class="fa-stack fa-4x">
              <i class="fa fa-circle fa-stack-2x text-primary"></i>
              <i class="fas fa-server fa-stack-1x fa-inverse"></i>
            </span>
            <h4 class="service-heading">Cloud and Infrastructure</h4>
            <p class="text-muted">
              Deep Understanding of building and deploying applications with
              Kubernetes, Docker, Flux, Prometheus, Apache Nifi, MongoDB, GitLab
              CI/CD, and GitHub actions
            </p>
          </div>
          <div class="col-md-3">
            <span class="fa-stack fa-4x">
              <i class="fa fa-circle fa-stack-2x text-primary"></i>
              <i class="fas fa-flask fa-stack-1x fa-inverse"></i>
            </span>
            <h4 class="service-heading">Data Science</h4>
            <p class="text-muted">
              Experience with Data Science toolkits such as NumPy, Pandas,
              Faiss, Gensim, SpaCy, NLTK, SciPy, and Matplotlib
            </p>
          </div>
          <div class="col-md-3">
            <span class="fa-stack fa-4x">
              <i class="fa fa-circle fa-stack-2x text-primary"></i>
              <i class="fa fa-code fa-stack-1x fa-inverse"></i>
            </span>
            <h4 class="service-heading">Programming Languages</h4>
            <p class="text-muted">
              In-depth understanding of Python, Cython, Java, and C. Experience
              with Javascript, C++, HTML, and
              <span class="latex">
                L
                <sup>a</sup>
                T
                <sub>e</sub>
                X
              </span>
              .
            </p>
          </div>
        </div>
      </div>
    </section>

    <!-- Projects Section -->
    <section id="projects">
      <div class="container">
        <div class="row">
          <div class="col-lg-12 text-center">
            <h2 class="section-heading">Projects</h2>
            <h3 class="section-subheading text-muted">
              See more of my work on
              <a href="https://www.github.com/blester125">GitHub</a>
              .
            </h3>
          </div>
        </div>
        <!-- <a href="", class="project-link"> -->
        <!-- <div class="row equal"> -->
        <!--     <div class="col-lg-10"> -->
        <!--         <div class="row"> -->
        <!--             <div class="col-lg-10"> -->
        <!--                 <h3 class="project-title"> -->
        <!--                     Project Title -->
        <!--                 </h3> -->
        <!--             </div> -->
        <!--             <div class="col-lg-2"> -->
        <!--                 <h6 class="project-type"> -->
        <!--                     Project Type -->
        <!--                 </h6> -->
        <!--             </div> -->
        <!--         </div> -->
        <!--         <div class="row"> -->
        <!--             <div class="col-lg-10"></div> -->
        <!--             <div class="col-lg-2"> -->
        <!--                 <p class="project-date">Project Date</p> -->
        <!--             </div> -->
        <!--         </div> -->
        <!--         <p class="project-content"> -->
        <!--           Project Content -->
        <!--         </p> -->
        <!--     </div> -->
        <!--     <div class="col-lg-2 project-image hidden-sm hidden-md"> -->
        <!--         Picture -->
        <!--         <img src="" class="img-thumbnail center-block" /> -->
        <!--     </div> -->
        <!-- </div> -->
        <!-- </a> -->

        <a href="https://github.com/blester125/text-rank" class="project-link">
          <div class="row equal">
            <div class="col-lg-10">
              <div class="row">
                <div class="col-lg-10">
                  <h3 class="project-title">
                    Text Rank
                  </h3>
                </div>
                <div class="col-lg-2">
                  <h6 class="project-type">
                    Personal Project/Open Source Library
                  </h6>
                </div>
              </div>
              <div class="row">
                <div class="col-lg-10"></div>
                <div class="col-lg-2">
                  <p class="project-date"></p>
                </div>
              </div>
              <p class="project-content">
                An implementation of Text Rank in Python that reproduces the
                results from the original paper. I currently use it as a vehicle
                for personal research: investigating if deep learning based
                sentence similarities will yield better summaries. Results
                forthcoming.
              </p>
            </div>
            <div class="col-lg-2 project-image hidden-sm hidden-md">
              <img
                src="static/img/project/text-rank.png"
                class="img-thumbnail center-block"
              />
            </div>
          </div>
        </a>

        <a
          href="https://github.com/blester125/string-distance"
          class="project-link"
        >
          <div class="row equal">
            <div class="col-lg-10">
              <div class="row">
                <div class="col-lg-10">
                  <h3 class="project-title">
                    String Distance
                  </h3>
                </div>
                <div class="col-lg-2">
                  <h6 class="project-type">
                    Open Source Library
                  </h6>
                </div>
              </div>
              <div class="row">
                <div class="col-lg-10"></div>
                <div class="col-lg-2">
                  <p class="project-date"></p>
                </div>
              </div>
              <p class="project-content">
                A collection of various minimum edit distance algorithms as well
                as token based methods like Jaccard overlap. The algorithms are
                implemented in Cython and scale well. The library is able to
                compute minimum edit distances between entire Wikipedia pages in
                under asecond.
              </p>
            </div>
            <div class="col-lg-2 project-image hidden-sm hidden-md">
              <img
                src="static/img/project/string-dist.png"
                class="img-thumbnail center-block"
              />
            </div>
          </div>
        </a>

        <a href="https://github.com/blester125/quick_knn" class="project-link">
          <div class="row equal">
            <div class="col-lg-10">
              <div class="row">
                <div class="col-lg-10">
                  <h3 class="project-title">
                    Quick KNN
                  </h3>
                </div>
                <div class="col-lg-2">
                  <h6 class="project-type">
                    Open Source Library
                  </h6>
                </div>
              </div>
              <div class="row">
                <div class="col-lg-10"></div>
                <div class="col-lg-2">
                  <p class="project-date"></p>
                </div>
              </div>
              <p class="project-content">
                Implementations of Locality Sensitive Hashing. Supports using
                MinHash to approximate Jaccard similarity and Random Hyperplanes
                for a cosine based LSH. Also provides utilties to estimate
                optimal band size for some desired threshold of similarity. This
                library enables users to find similar items in very large
                corpora quickly.
              </p>
            </div>
            <div class="col-lg-2 project-image hidden-sm hidden-md">
              <img
                src="static/img/project/random-hyperplanes.png"
                class="img-thumbnail center-block"
              />
            </div>
          </div>
        </a>

        <div class="row equal">
          <div class="col-lg-10">
            <div class="row">
              <div class="col-lg-10">
                <h3 class="project-title">
                  Dependency Parsing
                </h3>
              </div>
              <div class="col-lg-2">
                <h6 class="project-type">
                  Personal Project
                </h6>
              </div>
            </div>
            <div class="row">
              <div class="col-lg-10"></div>
              <div class="col-lg-2">
                <p class="project-date"></p>
              </div>
            </div>
            <p class="project-content">
              Dependency parsing via Deep Learning models written in PyTorch.
              Supports training parsers via dynamic oracles using either the Arc
              Eager or the Arc Hybrid transition scheme or a Graph based parser
              using Biaffine Attention. Currently working on creating a shared
              interface between the two parser types with plans to release it as
              an open source library
            </p>
          </div>
          <div class="col-lg-2 project-image hidden-sm hidden-md">
            <img
              src="static/img/project/dep-parse.webp"
              class="img-thumbnail center-block"
            />
          </div>
        </div>

        <div class="row equal">
          <div class="col-lg-10">
            <div class="row">
              <div class="col-lg-10">
                <h3 class="project-title">
                  PyPI Packages
                </h3>
              </div>
              <div class="col-lg-2">
                <h6 class="project-type">
                  Open Source Libraries
                </h6>
              </div>
            </div>
            <div class="row">
              <div class="col-lg-10"></div>
              <div class="col-lg-2">
                <p class="project-date"></p>
              </div>
            </div>
            <p class="project-content">
              I have a collection of libraries hosted on PyPI, most enable
              narrow data science verticals but some are generic utilities.
            </p>
            <ul class="project-list">
              <li>
                <a href="https://pypi.org/project/file-or-name/">
                  file-or-name
                </a>
                <p class="pypi-description">
                  A decorator that lets you mark a function parameter as a file.
                  This will automatically open the file when the function is
                  called. This lets you write easy to test function that assume
                  pre-opened files but allows your users to pass in file paths
                  as strings.
                </p>
              </li>
              <li>
                <a href="https://pypi.org/project/get-mnist/">get-mnist</a>
                <p class="pypi-description">
                  Lightweight utilities to download and load both the MNIST and
                  Fashion MNIST datasets. The only dependency is NumPy.
                </p>
              </li>
              <li>
                <a href="https://pypi.org/project/search-cli/">search-cli</a>
                <p class="pypi-description">
                  A GUI around surfraw that lets you open a search box from
                  anywhere, it also lets you do a search where the query is
                  whatever text is highlighted.
                </p>
              </li>
              <li>
                <a href="https://pypi.org/project/word-vectors/">
                  word-vectors
                </a>
                <p class="pypi-description">
                  Utilities to read and write common word vector formats such as
                  word2vec and glove. Also introduces a new format called Dense
                  which is a binary format like word2vec but the word is stored
                  in a fixed width. This uses a bit more disk space but allows
                  for faster reading and enables the ability to read from
                  multiple threads.
                </p>
              </li>
              <li>
                <a href="https://pypi.org/project/prehashed/">prehashed</a>
                <p class="pypi-description">
                  A dictionary subclass that stores the sha1 hash of keys rather
                  than the full key. This reduces storage space, for example if
                  your keys are long documents you can store and retrieve stats
                  about them without storing the whole document in memory.
                </p>
              </li>
              <li>
                <a href="https://pypi.org/project/true-case/">true-case</a>
                <p class="pypi-description">
                  An interface that gives the probability that a token should be
                  capitalized. Probabilities were estimated from the
                  CNN/DailyMail dataset.
                </p>
              </li>
              <li>
                <a href="https://pypi.org/project/quick-knn/">quick-knn</a>
                <p class="pypi-description">
                  An LSH implementation that support MinHash and Random
                  Hyperplanes.
                </p>
              </li>
              <li>
                <a href="https://pypi.org/project/string-distance/">
                  string-distance
                </a>
                <p class="pypi-description">
                  Cython implementations of various string distance algorithms.
                </p>
              </li>
              <li>
                <a href="https://pypi.org/project/delta-of-delta/">
                  delta-of-delta
                </a>
                <p class="pypi-description">
                  Pedagogical implementations of various time-stamp encoding
                  algorithms.
                </p>
              </li>
            </ul>
          </div>
          <div class="col-lg-2 project-image hidden-sm hidden-md">
            <img
              src="static/img/project/pypi.png"
              class="img-thumbnail center-block"
            />
          </div>
        </div>

        <a
          href="https://github.com/blester125/Decomposable_Attention"
          class="project-link"
        >
          <div class="row equal">
            <div class="col-lg-10">
              <div class="row">
                <div class="col-lg-10">
                  <h3 class="project-title">
                    Decomposable Attention
                  </h3>
                </div>
                <div class="col-lg-2">
                  <h6 class="project-type">
                    Personal Project
                  </h6>
                </div>
              </div>
              <div class="row">
                <div class="col-lg-10"></div>
                <div class="col-lg-2">
                  <p class="project-date">Winter 2017</p>
                </div>
              </div>
              <p class="project-content">
                A reimplementation of the paper
                <a href="https://arxiv.org/abs/1606.01933">
                  “A Decomposable Attention Model for Natural Language
                  Inference”
                </a>
                in DyNet. I was able to reproduce the paper results via
                extensive hyper parameter tuning
              </p>
            </div>
            <div class="col-lg-2 project-image hidden-sm hidden-md">
              <img
                src="static/img/project/attention.png"
                class="img-thumbnail center-block"
              />
            </div>
          </div>
        </a>

        <a
          href="https://github.com/blester125/Self_Driving_Network"
          class="project-link"
        >
          <div class="row equal">
            <div class="col-lg-10">
              <div class="row">
                <div class="col-lg-10">
                  <h3 class="project-title">
                    Steering Angles
                  </h3>
                </div>
                <div class="col-lg-2">
                  <h6 class="project-type">
                    Personal Project
                  </h6>
                </div>
              </div>
              <div class="row">
                <div class="col-lg-10"></div>
                <div class="col-lg-2">
                  <p class="project-date">Fall 2016</p>
                </div>
              </div>
              <p class="project-content">
                Using a deep convolutional network steering angles are predicted
                from a front facing camera. The network is 20 layers deep and
                uses various network architecture modifications to decrease
                training times. These include residual connections and batch
                normalization.
              </p>
            </div>
            <div class="col-lg-2 project-image hidden-sm hidden-md">
              <img
                src="static/img/project/drive.gif"
                class="img-thumbnail center-block"
              />
            </div>
          </div>
        </a>

        <a
          href="https://github.com/blester125/multi_digit_recognition"
          class="project-link"
        >
          <div class="row equal">
            <div class="col-lg-10">
              <div class="row">
                <div class="col-lg-10">
                  <h3 class="project-title">
                    Multi-Digit Recognition
                  </h3>
                </div>
                <div class="col-lg-2">
                  <h6 class="project-type">
                    Personal Project
                  </h6>
                </div>
              </div>
              <div class="row">
                <div class="col-lg-10"></div>
                <div class="col-lg-2">
                  <p class="project-date">Summer 2016</p>
                </div>
              </div>
              <p class="project-content">
                Using a deep convolutional network, written in Tensorflow,
                multi-digit sequences (up to five digits) are classified. This
                is done using an end-to-end network that recognize the digits in
                one step rather than creating separate parts that localize the
                digits, segment them, and then classify each digit individually.
                This network was trained using the Stanford Street View House
                Numbers Dataset and achieves 93.89 percent accuracy on the test
                dataset. Read the full write up
                <a
                  href="https://github.com/blester125/multi_digit_recognition/blob/master/Report.pdf"
                >
                  here
                </a>
              </p>
            </div>
            <div class="col-lg-2 project-image hidden-sm hidden-md">
              <img
                src="static/img/project/digits.png"
                class="img-thumbnail center-block"
              />
            </div>
          </div>
        </a>

        <a
          href="https://github.com/blester125/TCP-with-Minet"
          class="project-link"
        >
          <div class="row equal">
            <div class="col-lg-10">
              <div class="row">
                <div class="col-lg-10">
                  <h3 class="project-title">
                    RFC 793 Transmission Control Protocol
                  </h3>
                </div>
                <div class="col-lg-2">
                  <h6 class="project-type">
                    University of Pittsburgh
                  </h6>
                </div>
              </div>
              <div class="row">
                <div class="col-lg-10"></div>
                <div class="col-lg-2">
                  <p class="project-date">Fall 2015</p>
                </div>
              </div>
              <p class="project-content">
                Implementation of the Transmission Control Protocol (RFC 793)
                completed for Data Communications and Computer Networking. This
                implementation is fully functional TCP implementation required
                to ensure both packet delivery as well as in-order delivery of
                packets. This implementation also supports multiple in flight
                packets with using the "Go Back N" strategy. This requires the
                Minet framework to function.
              </p>
            </div>
            <div class="col-lg-2 project-image hidden-sm hidden-md">
              <img
                src="static/img/project/tcp-ascii.png"
                class="img-thumbnail center-block"
              />
            </div>
          </div>
        </a>

        <a href="https://github.com/blester125/CS_1645" class="project-link">
          <div class="row equal">
            <div class="col-lg-10">
              <div class="row">
                <div class="col-lg-10">
                  <h3 class="project-title">
                    Particle Simulation
                  </h3>
                </div>
                <div class="col-lg-2">
                  <h6 class="project-type">
                    University of Pittsburgh
                  </h6>
                </div>
              </div>
              <div class="row">
                <div class="col-lg-10"></div>
                <div class="col-lg-2">
                  <p class="project-date">Spring 2015</p>
                </div>
              </div>
              <p class="project-content">
                Particle interaction simulation written in C++. This simulation
                was written for parallel computation using the Message Passing
                Interface (MPI) and run on the Stampede super computer at Texas
                Advanced Computing Center. The simulation was carried out using
                the Ring Algorithm. Analysis of the program showed linear speed
                up as the number of processors was increased.
              </p>
            </div>
            <div class="col-lg-2 project-image hidden-sm hidden-md">
              <img
                src="static/img/project/hpc.jpg"
                class="img-thumbnail center-block"
              />
            </div>
          </div>
        </a>

        <a
          href="https://github.com/blester125/Secure-File-Sharing"
          class="project-link"
        >
          <div class="row equal">
            <div class="col-lg-10">
              <div class="row">
                <div class="col-lg-10">
                  <h3 class="project-title">
                    Secure File Sharing System
                  </h3>
                </div>
                <div class="col-lg-2">
                  <h6 class="project-type">
                    University of Pittsburgh
                  </h6>
                </div>
              </div>
              <div class="row">
                <div class="col-lg-10"></div>
                <div class="col-lg-2">
                  <p class="project-date">Spring: 2016</p>
                </div>
              </div>
              <p class="project-content">
                Distributed group-based file sharing system written in Java.
                This includes a multi-threaded group server that handles user
                authentication and distributes token to users. Multi-threaded
                file servers use the tokens to distribute files only to approved
                users. A GUI for clients to access files was also created. This
                Systems is secure as well. Cryptographic tools like symmetric
                and public key cryptography, Diffie Hellman key exchange and
                digital signatures are leverage to create secure authentication
                protocols that provide perfect forward security, repel man in
                the middle attacks, and provide plausible deniability. This
                system uses two-factor authentication via a Time based One Time
                Password (TOTP) scheme as outlined in RFC 6238.
              </p>
            </div>
            <div class="col-lg-2 project-image hidden-sm hidden-md">
              <img
                src="static/img/project/crypto.png"
                class="img-thumbnail center-block"
              />
            </div>
          </div>
        </a>

        <a
          href="https://github.com/blester125/facial_recognition"
          class="project-link"
        >
          <div class="row equal">
            <div class="col-lg-10">
              <div class="row">
                <div class="col-lg-10">
                  <h3 class="project-title">
                    Face Detection and Classification
                  </h3>
                </div>
                <div class="col-lg-2">
                  <h6 class="project-type">
                    Personal Project
                  </h6>
                </div>
              </div>
              <div class="row">
                <div class="col-lg-10"></div>
                <div class="col-lg-2">
                  <p class="project-date">Summer 2016</p>
                </div>
              </div>
              <p class="project-content">
                Facial detection and recognition in video streams. Facial
                detection is done with dlib's CUDA accelerated histogram of
                ordered gradients frontal face detector to find faces and then
                dlib again to estimate facial landmarks. These landmarks are
                then transformed using an affine transformation in openCV to
                center the face in the image. Embeddings are then generated
                using a deep neural network written in torch from the OpenFace
                project at Carnegie Mellon University. These embeddings are can
                then be classified by various machine learning techniques. This
                project used a support vector machine from Scikit-learn to
                classify the faces in the image.
              </p>
            </div>
            <div class="col-lg-2 project-image hidden-sm hidden-md">
              <img
                src="static/img/project/face.png"
                class="img-thumbnail center-block"
              />
            </div>
          </div>
        </a>

        <a
          href="https://github.com/blester125/CS_1622_Compilers"
          class="project-link"
        >
          <div class="row equal">
            <div class="col-lg-10">
              <div class="row">
                <div class="col-lg-10">
                  <h3 class="project-title">
                    Compiler
                  </h3>
                </div>
                <div class="col-lg-2">
                  <h6 class="project-type">
                    University of Pittsburgh
                  </h6>
                </div>
              </div>
              <div class="row">
                <div class="col-lg-10"></div>
                <div class="col-lg-2">
                  <p class="project-date">Spring 2016</p>
                </div>
              </div>
              <p class="project-content">
                A compiler written in C to compile an Object-Oriented language
                called MINI-Java. Lexical analysis is done using code generated
                by Lex based on specified regular expressions. Syntax analysis
                is done using a Context Free Grammar and Yacc. This syntactic
                analysis produces an Abstract Syntax Tree that is then parsed in
                the Semantic analysis phase.
                <!-- The code generation phase will produce assembly code targeted at the MIPS architecture. -->
              </p>
            </div>
            <div class="col-sm-2 project-image hidden-sm hidden-md">
              <img
                src="static/img/project/compiler.png"
                class="img-thumbnail center-block"
              />
            </div>
          </div>
        </a>
      </div>
    </section>

    <!-- Presentations section -->
    <section id="presentations" class="bg-light-gray">
      <div class="container">
        <div class="row">
          <div class="col-lg-12 text-center">
            <h2 class="section-heading">Presentations</h2>
          </div>
        </div>
        <!-- <div class="row equal"> -->
        <!--   <div class="col-sm-2 talk-image hidden-sm hidden-md"> -->
        <!--     <img src="" class="img-thumbnail center-block" /> -->
        <!--   </div> -->
        <!--   <div class="col-lg-10"> -->
        <!--     <h3 class="talk-title">Talk Title</h3> -->
        <!--     <h4 class="talk-location">Talk Location</h4> -->
        <!--     <p class="text-muted">Talk Date</p> -->
        <!--     <p class="text-muted"> -->
        <!--       Talk content -->
        <!--     </p> -->
        <!--          <a href="">slides</a> -->
        <!--          <a href="">video</a> -->
        <!--   </div> -->
        <!-- </div> -->
        <div class="row equal">
          <div class="col-sm-2 talk-image hidden-sm hidden-md">
            <img
              src="static/img/presentations/neurips.png"
              class="img-thumbnail center-block"
            />
          </div>
          <div class="col-lg-10">
            <h3 class="talk-title">NeurIPS Spotlight Talk on Mead-Baseline</h3>
            <h4 class="talk-location">NeurIPS OSS Workshop</h4>
            <p class="text-muted">December 2018</p>
            <p class="text-muted">
              A spotlight talk, at the Open Source Software workshop at NeurIPS
              2018, highlighting the advantages of using our open-source,
              model-building toolkit, Mead-Baseline, which provides high-level
              model abstractions, correct evaluation metrics, and fast runtimes.
              Mead-Baseline is the foundation of all Deep Learning work, in both
              research and production, at Interactions.
            </p>
          </div>
        </div>

        <div class="row equal">
          <div class="col-sm-2 talk-image hidden-sm hidden-md">
            <img
              src="static/img/presentations/calibration.png"
              class="img-thumbnail center-block"
            />
          </div>
          <div class="col-lg-10">
            <h3 class="talk-title">
              How do I trust my Model? Confidence in the Confidence of Neural
              Networks
            </h3>
            <h4 class="talk-location">
              Eastern Michigan University Machine Learning Conference<sup style="font-size: 12px;">*</sup>
            </h4>
            <p class="text-muted">March 2020, Upcoming</p>
            <p class="text-muted">
              In most settings, one trains a model and then evaluates it on some
              held out test set; however, there are some domains where one would
              rather have no answer than an uncertain one. For example, if you
              have a human in the loop you might want to send an example to the
              human to double check it rather than just using the label produced
              by the model. Confidence models allows one to make decisions about
              how much trust to put into a model's predictions.
            </p>
            <p class="text-muted">
              This talk outlines the idea of confidence modeling, techniques
              used to evaluate models that allow for the rejection of examples
              based on confidences, the difficulties of getting well calibrated
              posteriors from Deep Learning models, and a summary of current
              work—using calibration techniques and auxiliary models—to produce
              high-fidelity confidence scores in the Natural Language
              Understanding module of a real world Dialogue System.
            </p>
            <sub class="footnote text-muted"><sup class="text-muted">*</sup>Cancelled due to COVID-19</sub>
            <!-- <a href="">slides</a> -->
            <!-- <a href="">video</a> -->
          </div>
        </div>

        <div class="row equal">
          <div class="col-sm-2 talk-image hidden-sm hidden-md">
            <img
              src="static/img/presentations/masking.png"
              class="img-thumbnail center-block"
            />
          </div>
          <div class="col-lg-10">
            <h3 class="talk-title">
              Your Neural Network for Natural Language Processing is Probably
              Wrong
            </h3>
            <h4 class="talk-location">A2D-NLP</h4>
            <p class="text-muted">February 2020</p>
            <p class="text-muted">
              To efficiently train Deep Learning models processing multiple
              examples at once—aka batching—is paramount. The rub is that in NLP
              data often have differing sizes. We rectify this by adding empty
              data to smaller examples to bring them up to size: a technique we
              call padding. Padding comes with its own set of problems; if you
              aren't careful, calculations will include your padding elements
              and produce incorrect results.
            </p>
            <p class="text-muted">
              In this practitioner focused talk we cover how to batch, pad, and
              mask a range of neural network layers common in NLP including
              operations that obviously require masking like mean pooling, token
              level losses, and attention; complex operations like the CRF
              forward algorithm and Viterbi decoding; and subtle operations that
              you might not expect to require masking such as max pooling
              following a 1D convolution.
            </p>
            <a
              href="https://github.com/blester125/A2D-NLP-Talk-Feb-27-2020/blob/master/Your-Neural-Network-Is-Probably-Wrong.pdf"
            >
              slides
            </a>
          </div>
        </div>

        <div class="row equal">
          <div class="col-sm-2 talk-image hidden-sm hidden-md">
            <img
              src="static/img/presentations/numpy-cython.png"
              class="img-thumbnail center-block"
            />
          </div>
          <div class="col-lg-10">
            <h3 class="talk-title">Crunching Numbers with NumPy and Cython</h3>
            <h4 class="talk-location">Michigan Python Meetup</h4>
            <p class="text-muted">January 2020</p>
            <p class="text-muted">
              Based on a recent thread in the Ann Arbor data science Slack, this
              talk walks through the collaborative optimization of some numeric
              code. Beginning with a correct but slow implementation in Python,
              we will work though a series of improvements using NumPy, the
              Swiss army knife of scientific computing in Python. This talk will
              introduce core NumPy concepts like broadcasting and vectorization,
              and will wrap-up with a bespoke implementation in Cython for a
              blisteringly fast solution that can scale up to 10s of thousands
              of points in just second compared to the multi-hour runtime of a
              pure python soltuion.
            </p>
            <a
              href="https://github.com/blester125/MIPy-Talk-Jan-2-2020/blob/master/slides/slides.pdf"
            >
              slides
            </a>
          </div>
        </div>

        <div class="row equal">
          <div class="col-sm-2 talk-image hidden-sm hidden-md">
            <img
              src="static/img/presentations/char-input.png"
              class="img-thumbnail center-block"
            />
          </div>
          <div class="col-lg-10">
            <h3 class="talk-title">
              Input Representations of Deep Neural Networks
            </h3>
            <h4 class="talk-location">PyData Ann Arbor</h4>
            <p class="text-muted">October 2017</p>
            <p class="text-muted">
              A talk on creating robust models via learned character
              compositional input representations based on bLSTMs to support an
              open vocabulary for Deep Neural Networks.
            </p>
            <a
              href="https://github.com/blester125/language_model/blob/master/PyDataLightningBrianLester.pdf"
            >
              slides
            </a>
            <a href="presentations/pydata-2017.html">
              video
            </a>
          </div>
        </div>
      </div>
    </section>

    <!-- Publications section -->
    <section id="publications">
      <div class="container">
        <div class="row">
          <div class="col-lg-12 text-center">
            <h2 class="section-heading">Publications</h2>
          </div>
        </div>
        <div id="publications-container"></div>
      </div>
    </section>

    <!-- Education Section -->
    <section id="education" class="bg-light-gray">
      <div class="container">
        <div class="row col-lg-12 text-center">
          <h2 class="section-heading">Education</h2>
          <h3 class="section-subheading text-muted">
            The University of Pittsburgh
          </h3>
        </div>
        <div class="row text-center">
          <div class="col-md-4">
            <span class="fa-stack fa-4x">
              <i class="fa fa-circle fa-stack-2x text-primary"></i>
              <i class="fa fa-university fa-stack-1x fa-inverse"></i>
            </span>
            <h4 class="service-heading">Degrees</h4>
            <p class="text-muted" style="text-align: left;">
              Double Major at the University of Pittsburgh.
              <br />
              Bachelor of Science in Computer Science with honors.
              <br />
              Bachelor of Science in Neuroscience.
            </p>
          </div>
          <div class="col-md-4">
            <span class="fa-stack fa-4x">
              <i class="fa fa-circle fa-stack-2x text-primary"></i>
              <i class="fas fa-pencil-alt fa-stack-1x fa-inverse"></i>
            </span>
            <h4 class="service-heading">Significant Courses</h4>
            <p class="text-muted" style="text-align: left;">
              Data Communications and Computer Networks
              <br />
              High Performance Computing
              <br />
              Algorithm Design
              <br />
              Applied Cryptography and Network Security
              <br />
              Compiler Design
              <br />
              Programming Languages for Web Applications
              <br />
              Software Quality Assurance
              <br />
            </p>
          </div>
          <div class="col-md-4">
            <span class="fa-stack fa-4x">
              <i class="fa fa-circle fa-stack-2x text-primary"></i>
              <i class="fa fa-laptop fa-stack-1x fa-inverse"></i>
            </span>
            <h4 class="service-heading">Continuous Learning</h4>
            <p class="text-muted" style="text-align: left;">
              Audit lectures and completed assignments for many online courses
              including, Coursea Machine Learning, Udacity Machine Learning
              Nanodegree, and Stanford CS 224n Deep Learning for Natural
              Language Processing.
            </p>
          </div>
        </div>
      </div>
    </section>

    <footer class="bg-dark-gray">
      <div class="container">
        <div class="row">
          <div class="col-md-4">
            <span class="copyright">Brian Lester, 2020</span>
          </div>
          <div class="col-md-4">
            <!-- This should match the top one -->
            <ul class="list-inline social-buttons">
              <li>
                <a href="https://twitter.com/blester125">
                  <i class="fab fa-twitter"></i>
                </a>
              </li>

              <li>
                <a href="https://www.linkedin.com/in/blester125">
                  <i class="fab fa-linkedin"></i>
                </a>
              </li>
              <li>
                <a
                  href="https://scholar.google.com/citations?user=OWSQqZMAAAAJ&hl=en"
                >
                  <i class="ai ai-google-scholar"></i>
                </a>
              </li>

              <li>
                <a href="https://pypi.org/user/BLester125/">
                  <i class="fab fa-python"></i>
                </a>
              </li>
              <li>
                <a href="https://github.com/blester125">
                  <i class="fab fa-github"></i>
                </a>
              </li>
            </ul>
          </div>
          <div class="col-md-4">
            <ul class="list-inline quicklinks">
              <li>
                Design based on "
                <a href="http://startbootstrap.com/template-overviews/agency/">
                  Agency
                </a>
                " template.
              </li>
            </ul>
          </div>
        </div>
      </div>
    </footer>
  </body>
</html>
