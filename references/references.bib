@InProceedings{jindal-etal-2019-effective,
    title = "An Effective Label Noise Model for {DNN} Text Classification",
    author = "Jindal, Ishan and Pressel, Daniel and Lester, Brian and Nokleby, Matthew",
    booktitle = "Proceedings of the 2019 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)",
    month = jun,
    year = "2019",
    address = "Minneapolis, Minnesota",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/N19-1328",
    doi = "10.18653/v1/N19-1328",
    pages = "3246--3256",
    abstract = "Because large, human-annotated datasets suffer from labeling errors, it is crucial to be able to train deep neural networks in the presence of label noise. While training image classification models with label noise have received much attention, training text classification models have not. In this paper, we propose an approach to training deep networks that is robust to label noise. This approach introduces a non-linear processing layer (noise model) that models the statistics of the label noise into a convolutional neural network (CNN) architecture. The noise model and the CNN weights are learned jointly from noisy training data, which prevents the model from overfitting to erroneous labels. Through extensive experiments on several text classification datasets, we show that this approach enables the CNN to learn better sentence representations and is robust even to extreme label noise. We find that proper initialization and regularization of this noise model is critical. Further, by contrast to results focusing on large batch sizes for mitigating label noise for image classification, we find that altering the batch size does not have much effect on classification performance.",
}

@InProceedings{pressel-etal-2018-baseline,
    title = "{B}aseline: A Library for Rapid Modeling, Experimentation and Development of Deep Learning Algorithms targeting {NLP}",
    author = "Pressel, Daniel and Ray Choudhury, Sagnik and Lester, Brian and Zhao, Yanjie and Barta, Matt",
    booktitle = "Proceedings of Workshop for {NLP} Open Source Software ({NLP}-{OSS})",
    month = jul,
    year = "2018",
    address = "Melbourne, Australia",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W18-2506",
    doi = "10.18653/v1/W18-2506",
    pages = "34--40",
    abstract = "We introduce Baseline: a library for reproducible deep learning research and fast model development for NLP. The library provides easily extensible abstractions and implementations for data loading, model development, training and export of deep learning architectures. It also provides implementations for simple, high-performance, deep learning models for various NLP tasks, against which newly developed models can be compared. Deep learning experiments are hard to reproduce, Baseline provides functionalities to track them. The goal is to allow a researcher to focus on model development, delegating the repetitive tasks to the library.",
}

@misc{lester-2018-dynamically,
  title={Dynamically Adjusting a Voice Recognition System},
  author={Lester, Brian and Panainte, Sorin M},
  year={2018},
  month={may # "~29"},
  journal={US Patent 9,984,688},
  url={https://patentimages.storage.googleapis.com/2c/b0/bd/d319d8645faa83/US9984688.pdf}
}


@article{lester2020computationally,
  title={Computationally Efficient NER Taggers with Combined Embeddings and Constrained Decoding},
  author={Lester, Brian and Pressel, Daniel and Hemmeter, Amy and Choudhury, Sagnik Ray},
  journal={arXiv preprint arXiv:2001.01167},
  year={2020},
  url={https://arxiv.org/pdf/2001.01167.pdf}
}


@article{pressel2018baseline,
  title={Baseline: Strong, Extensible, Reproducible, Deep Learning Baselines for NLP},
  author={Pressel, Daniel and Lester, Brian and Choudhury, Sagnik Ray and Barta, Matt and Zhao, Yanjie and Hemmeter, Amy},
  year={2018},
  url={https://openreview.net/pdf?id=rkxp6taEhQ},
  address = "Montreal Quebec",
  journal= "Neural Information Processing Systems Open Source Software Workshop"
}
